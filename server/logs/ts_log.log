2022-01-20T15:26:17,589 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T15:26:17,589 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T15:26:17,667 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T15:26:17,667 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T15:26:17,781 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice=nice-distilbertv2.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T15:26:17,781 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice=nice-distilbertv2.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T15:26:17,786 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-distilbertv2.mar
2022-01-20T15:26:17,786 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-distilbertv2.mar
2022-01-20T15:26:21,517 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice
2022-01-20T15:26:21,517 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice
2022-01-20T15:26:21,517 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:26:21,517 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:26:21,518 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice loaded.
2022-01-20T15:26:21,518 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice loaded.
2022-01-20T15:26:21,518 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice, count: 1
2022-01-20T15:26:21,518 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice, count: 1
2022-01-20T15:26:21,525 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:21,525 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T15:26:21,525 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:21,525 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T15:26:21,582 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-20T15:26:21,582 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-20T15:26:21,582 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T15:26:21,582 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T15:26:21,583 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-20T15:26:21,583 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-20T15:26:21,583 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T15:26:21,583 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T15:26:21,584 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-20T15:26:21,584 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-20T15:26:21,721 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T15:26:21,721 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T15:26:21,821 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642710381
2022-01-20T15:26:21,822 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:86.64562225341797|#Level:Host|#hostname:MeshifyC,timestamp:1642710381
2022-01-20T15:26:21,823 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:843.7921905517578|#Level:Host|#hostname:MeshifyC,timestamp:1642710381
2022-01-20T15:26:21,823 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:90.7|#Level:Host|#hostname:MeshifyC,timestamp:1642710381
2022-01-20T15:26:21,824 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20977.8984375|#Level:Host|#hostname:MeshifyC,timestamp:1642710381
2022-01-20T15:26:21,824 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11715.94140625|#Level:Host|#hostname:MeshifyC,timestamp:1642710381
2022-01-20T15:26:21,825 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:35.8|#Level:Host|#hostname:MeshifyC,timestamp:1642710381
2022-01-20T15:26:23,844 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:26:23,845 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]11048
2022-01-20T15:26:23,845 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:26:23,846 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change null -> WORKER_STARTED
2022-01-20T15:26:23,846 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change null -> WORKER_STARTED
2022-01-20T15:26:23,846 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:26:23,848 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:23,848 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:23,855 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:26:23,857 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710383857
2022-01-20T15:26:23,857 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710383857
2022-01-20T15:26:23,880 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:26:24,379 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:26:24,380 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:26:24,380 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:24,380 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:26:24,380 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:24,381 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:24,381 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:26:24,381 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:24,382 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:26:24,383 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:26:24,383 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:26:24,383 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:26:24,384 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:26:24,384 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:26:24,384 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 112, in load
2022-01-20T15:26:24,385 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-20T15:26:24,385 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-01-20T15:26:24,386 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-01-20T15:26:24,386 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\c25de70aa87c41179205e6b9834537ab\nice-distilbertv2-handler.py", line 108, in handle
2022-01-20T15:26:24,386 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     raise e
2022-01-20T15:26:24,387 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\c25de70aa87c41179205e6b9834537ab\nice-distilbertv2-handler.py", line 97, in handle
2022-01-20T15:26:24,387 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-01-20T15:26:24,388 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\c25de70aa87c41179205e6b9834537ab\nice-distilbertv2-handler.py", line 31, in initialize
2022-01-20T15:26:24,388 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-01-20T15:26:24,388 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\transformers\models\auto\auto_factory.py", line 396, in from_pretrained
2022-01-20T15:26:24,382 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:24,389 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2022-01-20T15:26:24,382 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:24,389 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:24,389 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\transformers\models\auto\configuration_auto.py", line 558, in from_pretrained
2022-01-20T15:26:24,389 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:24,390 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:24,390 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2022-01-20T15:26:24,390 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:24,391 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:24,391 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\transformers\configuration_utils.py", line 550, in get_config_dict
2022-01-20T15:26:24,391 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:24,393 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:24,392 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     resolved_config_file = cached_path(
2022-01-20T15:26:24,393 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:24,394 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:26:24,393 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\transformers\file_utils.py", line 1509, in cached_path
2022-01-20T15:26:24,394 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:24,394 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:26:24,394 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:24,395 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:24,395 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:25,399 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:25,399 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:26,468 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:26:26,468 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]4272
2022-01-20T15:26:26,469 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:26,469 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:26:26,469 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:26,469 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:26,469 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:26:26,469 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:26,471 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710386471
2022-01-20T15:26:26,471 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:26:26,471 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710386471
2022-01-20T15:26:26,478 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:26:26,809 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:26:26,809 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:26:26,810 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:26,810 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:26:26,810 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:26,811 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:26,811 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:26:26,811 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:26,812 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:26,811 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:26:26,812 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:26,813 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:26,812 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:26:26,813 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:26,813 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:26,813 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:26:26,813 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:26,814 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:26,813 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:26:26,814 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:26,816 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:26,815 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:26:26,816 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:26,816 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:26:26,816 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:26:26,817 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:26,816 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:26:26,817 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:26,818 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:26,818 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:27,820 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:27,820 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:28,890 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:26:28,891 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]25760
2022-01-20T15:26:28,892 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:28,892 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:26:28,892 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:28,893 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:28,892 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:26:28,893 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:28,895 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710388895
2022-01-20T15:26:28,894 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:26:28,895 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710388895
2022-01-20T15:26:28,904 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:26:29,239 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:26:29,239 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:29,239 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:26:29,239 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:29,241 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:29,241 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:26:29,241 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:29,242 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:29,242 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:26:29,242 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:29,243 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:29,242 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:26:29,243 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:29,243 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:29,243 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:26:29,243 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:29,244 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:29,244 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:26:29,244 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:29,246 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:29,245 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:26:29,246 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:29,246 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T15:26:29,246 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:26:29,247 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:29,246 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T15:26:29,247 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:29,248 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:29,248 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:31,254 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:31,254 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:35,548 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:26:35,548 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]7768
2022-01-20T15:26:35,548 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:35,548 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:26:35,548 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:35,549 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:35,549 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:26:35,549 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:35,551 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710395551
2022-01-20T15:26:35,551 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:26:35,551 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710395551
2022-01-20T15:26:35,559 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:26:35,889 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:26:35,889 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:35,889 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:26:35,889 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:35,890 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:35,890 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:26:35,890 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:35,890 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:35,890 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:26:35,890 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:35,891 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:35,891 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:26:35,891 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:35,892 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:35,892 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:26:35,892 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:35,893 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:35,892 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:26:35,893 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:35,894 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:35,894 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:26:35,894 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:35,895 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T15:26:35,895 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:26:35,895 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:35,895 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T15:26:35,895 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:35,897 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:35,897 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:38,901 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:38,901 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:39,976 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:26:39,977 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]27244
2022-01-20T15:26:39,977 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:39,977 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:26:39,977 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:39,977 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:26:39,977 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:39,977 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:39,978 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710399978
2022-01-20T15:26:39,978 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:26:39,978 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710399978
2022-01-20T15:26:39,986 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:26:40,325 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:26:40,325 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:40,325 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:26:40,325 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:40,327 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:40,327 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:26:40,327 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:40,329 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:40,328 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:26:40,329 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:40,330 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:40,329 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:26:40,330 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:40,330 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:40,330 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:26:40,330 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:40,331 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:40,331 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:26:40,331 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:40,333 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:40,333 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:26:40,333 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:40,334 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T15:26:40,334 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:26:40,335 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:40,334 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T15:26:40,335 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:40,335 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:40,335 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:45,346 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:45,346 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:46,429 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:26:46,430 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]26868
2022-01-20T15:26:46,430 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:46,430 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:26:46,430 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:46,431 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:46,431 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:26:46,431 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:46,433 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710406433
2022-01-20T15:26:46,433 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:26:46,433 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710406433
2022-01-20T15:26:46,441 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:26:46,771 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:26:46,772 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:46,772 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:26:46,772 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:46,773 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:46,772 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:26:46,773 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:46,773 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:46,773 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:26:46,773 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:46,774 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:46,774 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:26:46,774 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:46,775 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:46,774 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:26:46,775 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:46,775 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:46,775 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:26:46,775 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:46,777 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:46,777 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:26:46,777 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:46,778 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T15:26:46,777 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:26:46,778 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:46,778 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T15:26:46,778 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:46,780 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:46,780 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:54,791 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:54,791 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:26:55,853 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:26:55,854 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]26436
2022-01-20T15:26:55,855 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:55,855 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:26:55,855 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:26:55,855 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:55,855 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:26:55,855 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:26:55,857 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710415857
2022-01-20T15:26:55,857 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:26:55,857 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710415857
2022-01-20T15:26:55,863 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:26:56,196 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:26:56,197 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:56,197 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:26:56,197 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:26:56,198 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:56,197 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:26:56,198 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:26:56,199 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:56,198 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:26:56,199 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:26:56,199 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:56,199 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:26:56,199 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:26:56,200 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:56,200 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:26:56,200 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:26:56,201 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:56,200 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:26:56,201 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:26:56,202 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:56,202 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:26:56,202 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:26:56,203 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T15:26:56,203 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:26:56,203 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:56,203 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T15:26:56,203 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:26:56,205 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:26:56,205 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:27:09,212 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:27:09,212 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:27:10,274 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:27:10,274 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]18844
2022-01-20T15:27:10,275 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:27:10,275 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:27:10,275 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:27:10,275 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:27:10,275 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:27:10,275 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:27:10,277 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710430277
2022-01-20T15:27:10,277 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710430277
2022-01-20T15:27:10,277 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:27:10,284 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:27:10,608 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:27:10,608 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:27:10,608 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:27:10,608 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:27:10,612 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:27:10,609 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:27:10,612 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:27:10,612 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:27:10,613 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:27:10,613 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:27:10,613 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:27:10,614 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:27:10,613 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:27:10,614 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:27:10,614 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:27:10,614 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:27:10,614 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:27:10,615 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:27:10,615 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:27:10,615 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:27:10,617 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:27:10,617 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:27:10,617 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:27:10,618 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T15:27:10,617 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:27:10,618 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:27:10,618 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T15:27:10,618 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:27:10,619 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:27:10,619 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:27:11,742 [INFO ] W-9000-nice_1.0 ACCESS_LOG - /127.0.0.1:49233 "GET /ping HTTP/1.1" 200 3
2022-01-20T15:27:11,742 [INFO ] W-9000-nice_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T15:27:21,812 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642710441
2022-01-20T15:27:21,812 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:86.650390625|#Level:Host|#hostname:MeshifyC,timestamp:1642710441
2022-01-20T15:27:21,813 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:843.7874221801758|#Level:Host|#hostname:MeshifyC,timestamp:1642710441
2022-01-20T15:27:21,813 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:90.7|#Level:Host|#hostname:MeshifyC,timestamp:1642710441
2022-01-20T15:27:21,814 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20926.91796875|#Level:Host|#hostname:MeshifyC,timestamp:1642710441
2022-01-20T15:27:21,814 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:11766.92578125|#Level:Host|#hostname:MeshifyC,timestamp:1642710441
2022-01-20T15:27:21,814 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:36.0|#Level:Host|#hostname:MeshifyC,timestamp:1642710441
2022-01-20T15:27:31,630 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:27:31,630 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:27:32,689 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:27:32,690 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]3580
2022-01-20T15:27:32,691 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:27:32,691 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:27:32,691 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:27:32,691 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:27:32,691 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:27:32,691 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:27:32,693 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710452693
2022-01-20T15:27:32,693 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:27:32,693 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710452693
2022-01-20T15:27:32,701 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:27:33,020 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:27:33,021 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:27:33,021 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:27:33,021 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:27:33,022 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:27:33,022 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:27:33,022 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:27:33,023 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:27:33,023 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:27:33,023 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:27:33,024 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:27:33,023 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:27:33,024 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:27:33,024 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:27:33,024 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:27:33,024 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:27:33,025 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:27:33,024 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:27:33,025 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:27:33,027 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:27:33,026 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:27:33,027 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:27:33,027 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T15:27:33,027 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:27:33,027 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:27:33,027 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T15:27:33,027 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:27:33,029 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:27:33,029 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:27:41,700 [INFO ] W-9000-nice_1.0 ACCESS_LOG - /127.0.0.1:49233 "GET /ping HTTP/1.1" 200 1
2022-01-20T15:27:41,700 [INFO ] W-9000-nice_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T15:28:07,029 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:28:07,029 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:28:08,108 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:28:08,109 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]28572
2022-01-20T15:28:08,110 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:28:08,110 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:28:08,110 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:28:08,110 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:28:08,110 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:28:08,110 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:28:08,112 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710488112
2022-01-20T15:28:08,112 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710488112
2022-01-20T15:28:08,112 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:28:08,119 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:28:08,449 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:28:08,450 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:28:08,450 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:28:08,450 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:28:08,451 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:28:08,451 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:28:08,451 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:28:08,451 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:28:08,451 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:28:08,452 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:28:08,451 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:28:08,452 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:28:08,452 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:28:08,452 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:28:08,453 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:28:08,453 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:28:08,453 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:28:08,454 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:28:08,453 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:28:08,454 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:28:08,455 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:28:08,455 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:28:08,455 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:28:08,456 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T15:28:08,456 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:28:08,456 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:28:08,456 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T15:28:08,456 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:28:08,458 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:28:08,458 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:28:27,235 [INFO ] nioEventLoopGroup-3-1 ACCESS_LOG - /127.0.0.1:49233 "GET /models HTTP/1.1" 404 1
2022-01-20T15:28:27,235 [INFO ] nioEventLoopGroup-3-1 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T15:28:40,578 [INFO ] W-9000-nice_1.0 ACCESS_LOG - /127.0.0.1:49266 "GET /ping HTTP/1.1" 200 0
2022-01-20T15:28:40,578 [INFO ] W-9000-nice_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T15:28:54,619 [INFO ] W-9000-nice_1.0 ACCESS_LOG - /127.0.0.1:49266 "GET /ping/ HTTP/1.1" 200 0
2022-01-20T15:28:54,619 [INFO ] W-9000-nice_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T15:29:03,472 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:03,472 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:04,535 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:29:04,536 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]26896
2022-01-20T15:29:04,536 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:29:04,536 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:29:04,536 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:29:04,536 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:04,536 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T15:29:04,536 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:04,537 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710544537
2022-01-20T15:29:04,537 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:29:04,537 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710544537
2022-01-20T15:29:04,547 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:29:04,869 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:29:04,870 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:04,870 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:29:04,870 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:04,870 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:29:04,870 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:04,870 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:04,870 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:29:04,870 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:29:04,870 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:04,870 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:29:04,870 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:04,870 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:29:04,870 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:04,870 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:29:04,870 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:04,871 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:04,871 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:29:04,871 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:04,871 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:29:04,871 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:04,871 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 112, in load
2022-01-20T15:29:04,871 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:04,871 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:04,871 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-20T15:29:04,871 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:04,872 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T15:29:04,871 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-01-20T15:29:04,873 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:04,872 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T15:29:04,873 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:04,875 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:29:04,875 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:29:49,048 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T15:29:49,048 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T15:29:49,108 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T15:29:49,108 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T15:29:49,219 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: c:\users\adib\anaconda3\python.exe
Config file: logs\config\20220120152621584-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice=nice-distilbertv2.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T15:29:49,219 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: c:\users\adib\anaconda3\python.exe
Config file: logs\config\20220120152621584-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice=nice-distilbertv2.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T15:29:49,223 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220120152621584-startup.cfg",
  "modelCount": 1,
  "created": 1642710381585,
  "models": {
    "nice": {
      "1.0": {
        "defaultVersion": true,
        "marName": "nice-distilbertv2.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-01-20T15:29:49,223 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220120152621584-startup.cfg",
  "modelCount": 1,
  "created": 1642710381585,
  "models": {
    "nice": {
      "1.0": {
        "defaultVersion": true,
        "marName": "nice-distilbertv2.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-01-20T15:29:49,227 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220120152621584-startup.cfg
2022-01-20T15:29:49,227 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220120152621584-startup.cfg
2022-01-20T15:29:49,228 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220120152621584-startup.cfg validated successfully
2022-01-20T15:29:49,228 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220120152621584-startup.cfg validated successfully
2022-01-20T15:29:52,775 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice
2022-01-20T15:29:52,775 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice
2022-01-20T15:29:52,775 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:29:52,775 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:29:52,776 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:29:52,776 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:29:52,776 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice loaded.
2022-01-20T15:29:52,776 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice loaded.
2022-01-20T15:29:52,777 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice, count: 1
2022-01-20T15:29:52,777 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice, count: 1
2022-01-20T15:29:52,783 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:52,783 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:52,783 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T15:29:52,783 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T15:29:52,841 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-20T15:29:52,841 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-20T15:29:52,841 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T15:29:52,841 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T15:29:52,842 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-20T15:29:52,842 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-20T15:29:52,842 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T15:29:52,842 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T15:29:52,843 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-20T15:29:52,843 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-20T15:29:52,977 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T15:29:52,977 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T15:29:53,060 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642710593
2022-01-20T15:29:53,061 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:86.40034866333008|#Level:Host|#hostname:MeshifyC,timestamp:1642710593
2022-01-20T15:29:53,062 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:844.0374641418457|#Level:Host|#hostname:MeshifyC,timestamp:1642710593
2022-01-20T15:29:53,062 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:90.7|#Level:Host|#hostname:MeshifyC,timestamp:1642710593
2022-01-20T15:29:53,062 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20935.21875|#Level:Host|#hostname:MeshifyC,timestamp:1642710593
2022-01-20T15:29:53,063 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11758.625|#Level:Host|#hostname:MeshifyC,timestamp:1642710593
2022-01-20T15:29:53,063 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:36.0|#Level:Host|#hostname:MeshifyC,timestamp:1642710593
2022-01-20T15:29:53,891 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:29:53,891 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]20840
2022-01-20T15:29:53,892 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:29:53,892 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change null -> WORKER_STARTED
2022-01-20T15:29:53,892 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:29:53,892 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change null -> WORKER_STARTED
2022-01-20T15:29:53,895 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:53,895 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:53,901 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:29:53,903 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710593903
2022-01-20T15:29:53,903 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710593903
2022-01-20T15:29:53,917 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:29:54,267 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:29:54,268 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:29:54,269 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:54,269 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:54,269 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:54,269 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:29:54,269 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:54,269 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:29:54,270 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:29:54,270 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:29:54,271 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:29:54,271 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:29:54,271 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:29:54,272 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:29:54,272 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-01-20T15:29:54,272 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-20T15:29:54,273 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-01-20T15:29:54,273 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-01-20T15:29:54,274 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\a847934dbbef4a9cbaf9ff144d0455e6\nice-distilbertv2-handler.py", line 108, in handle
2022-01-20T15:29:54,274 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     raise e
2022-01-20T15:29:54,274 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\a847934dbbef4a9cbaf9ff144d0455e6\nice-distilbertv2-handler.py", line 97, in handle
2022-01-20T15:29:54,274 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-01-20T15:29:54,275 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\a847934dbbef4a9cbaf9ff144d0455e6\nice-distilbertv2-handler.py", line 31, in initialize
2022-01-20T15:29:54,275 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-01-20T15:29:54,276 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 396, in from_pretrained
2022-01-20T15:29:54,270 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:54,276 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2022-01-20T15:29:54,270 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:54,277 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:54,276 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\models\auto\configuration_auto.py", line 558, in from_pretrained
2022-01-20T15:29:54,277 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:54,277 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:54,277 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2022-01-20T15:29:54,277 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:54,278 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:54,278 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\configuration_utils.py", line 550, in get_config_dict
2022-01-20T15:29:54,278 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:54,279 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:54,280 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:29:54,278 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     resolved_config_file = cached_path(
2022-01-20T15:29:54,280 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:29:54,279 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:54,283 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:29:54,282 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\file_utils.py", line 1509, in cached_path
2022-01-20T15:29:54,283 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:54,283 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:29:54,283 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:55,297 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:55,297 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:56,327 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:29:56,328 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]13176
2022-01-20T15:29:56,328 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:29:56,328 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:29:56,328 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:29:56,329 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:56,329 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:29:56,329 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:56,331 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710596330
2022-01-20T15:29:56,331 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710596330
2022-01-20T15:29:56,331 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:29:56,337 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:29:56,611 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:29:56,611 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:56,611 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:29:56,611 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:56,612 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:56,612 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:29:56,612 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:56,613 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:56,612 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:29:56,613 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:56,613 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:56,613 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:29:56,613 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:56,614 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:56,614 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:29:56,614 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:56,615 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:56,614 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:29:56,615 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:56,615 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:56,615 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:29:56,615 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:56,616 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:29:56,616 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:29:56,616 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:56,616 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:29:56,616 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:56,617 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:29:56,617 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:29:57,618 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:57,618 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:29:58,636 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:29:58,636 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]27852
2022-01-20T15:29:58,637 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:29:58,637 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:29:58,637 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:29:58,638 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:58,637 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:29:58,638 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:29:58,639 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710598639
2022-01-20T15:29:58,639 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:29:58,639 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710598639
2022-01-20T15:29:58,646 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:29:58,915 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:29:58,915 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:58,915 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:29:58,915 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:29:58,916 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:58,916 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:29:58,916 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:29:58,917 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:58,916 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:29:58,917 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:29:58,917 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:58,917 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:29:58,917 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:29:58,918 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:58,918 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:29:58,918 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:29:58,919 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:58,918 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:29:58,919 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:29:58,919 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:58,919 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:29:58,919 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:29:58,920 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T15:29:58,920 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:29:58,920 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:58,920 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T15:29:58,921 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:29:58,920 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:29:58,921 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:00,924 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:00,924 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:01,947 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:30:01,948 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]9552
2022-01-20T15:30:01,949 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:01,949 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:30:01,949 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:01,950 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:01,949 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:30:01,950 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:01,951 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710601951
2022-01-20T15:30:01,951 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:30:01,951 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710601951
2022-01-20T15:30:01,958 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:30:02,228 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:30:02,229 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:02,229 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:30:02,229 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:02,230 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:02,230 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:30:02,230 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:02,231 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:02,231 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:30:02,231 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:02,231 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:02,231 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:30:02,231 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:02,232 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:30:02,232 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:02,232 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:02,232 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:02,232 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:30:02,233 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:30:02,232 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:02,234 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:02,233 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:30:02,234 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:02,234 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T15:30:02,234 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:30:02,234 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:02,235 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:02,234 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T15:30:02,235 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:02,234 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:05,238 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:05,238 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:06,280 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:30:06,281 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]27396
2022-01-20T15:30:06,281 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:06,281 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:30:06,281 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:06,282 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:06,282 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:30:06,282 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:06,284 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710606284
2022-01-20T15:30:06,283 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:30:06,284 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710606284
2022-01-20T15:30:06,290 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:30:06,562 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:30:06,563 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:06,563 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:30:06,563 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:06,564 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:06,564 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:30:06,564 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:06,565 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:06,564 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:30:06,565 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:06,565 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:06,565 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:30:06,565 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:06,566 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:06,566 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:30:06,566 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:06,567 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:06,566 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:30:06,567 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:06,568 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:06,567 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:30:06,568 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:06,569 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T15:30:06,569 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:06,568 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:30:06,570 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:06,569 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:06,569 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T15:30:06,570 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:11,576 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:11,576 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:39,949 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:30:39,950 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]23116
2022-01-20T15:30:39,952 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:39,952 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:30:39,952 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:39,953 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:39,952 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:30:39,953 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:39,955 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710639955
2022-01-20T15:30:39,955 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:30:39,955 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710639955
2022-01-20T15:30:39,962 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:30:40,243 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:30:40,243 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:40,243 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:30:40,243 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:40,245 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:40,244 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:30:40,245 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:40,245 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:40,245 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:30:40,245 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:40,246 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:40,246 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:30:40,246 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:40,247 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:40,247 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:30:40,247 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:40,248 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:40,247 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:30:40,248 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:40,249 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:40,248 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:30:40,249 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:40,249 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T15:30:40,249 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:30:40,250 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:40,250 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:40,249 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T15:30:40,250 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:40,250 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:46,602 [INFO ] W-9000-nice_1.0 ACCESS_LOG - /127.0.0.1:49349 "GET /ping HTTP/1.1" 200 3
2022-01-20T15:30:46,602 [INFO ] W-9000-nice_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T15:30:48,260 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:48,260 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:30:49,290 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:30:49,290 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]22756
2022-01-20T15:30:49,291 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:49,291 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:30:49,291 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:30:49,291 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:49,291 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:30:49,291 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:30:49,293 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710649293
2022-01-20T15:30:49,293 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:30:49,293 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710649293
2022-01-20T15:30:49,300 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:30:49,568 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:30:49,568 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:49,568 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:30:49,568 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:30:49,569 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:49,569 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:30:49,569 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:30:49,570 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:49,570 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:30:49,570 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:30:49,571 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:49,570 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:30:49,571 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:30:49,572 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:49,571 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:30:49,572 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:30:49,572 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:49,572 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:30:49,572 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:30:49,573 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:49,573 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:30:49,573 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:30:49,574 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T15:30:49,573 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:30:49,574 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:49,574 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T15:30:49,574 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:49,574 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:30:49,574 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:30:53,062 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642710653
2022-01-20T15:30:53,062 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:86.3996810913086|#Level:Host|#hostname:MeshifyC,timestamp:1642710653
2022-01-20T15:30:53,063 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:844.0381317138672|#Level:Host|#hostname:MeshifyC,timestamp:1642710653
2022-01-20T15:30:53,064 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:90.7|#Level:Host|#hostname:MeshifyC,timestamp:1642710653
2022-01-20T15:30:53,064 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20939.20703125|#Level:Host|#hostname:MeshifyC,timestamp:1642710653
2022-01-20T15:30:53,064 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11754.63671875|#Level:Host|#hostname:MeshifyC,timestamp:1642710653
2022-01-20T15:30:53,065 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:36.0|#Level:Host|#hostname:MeshifyC,timestamp:1642710653
2022-01-20T15:31:02,583 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:31:02,583 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:31:03,619 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:31:03,619 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]9276
2022-01-20T15:31:03,620 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:31:03,620 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:31:03,620 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:31:03,620 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:31:03,620 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:31:03,620 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:31:03,622 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710663622
2022-01-20T15:31:03,622 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:31:03,622 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710663622
2022-01-20T15:31:03,631 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:31:03,896 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:31:03,896 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:31:03,896 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:31:03,896 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:31:03,898 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:31:03,897 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:31:03,898 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:31:03,898 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:31:03,898 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:31:03,898 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:31:03,899 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:31:03,899 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:31:03,899 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:31:03,900 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:31:03,899 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:31:03,900 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:31:03,900 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:31:03,900 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:31:03,900 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:31:03,901 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:31:03,901 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:31:03,901 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:31:03,902 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T15:31:03,901 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:31:03,902 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:31:03,902 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:31:03,902 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:31:03,902 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T15:31:03,902 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:31:24,914 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:31:24,914 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:31:25,975 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:31:25,976 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]27148
2022-01-20T15:31:25,977 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:31:25,977 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:31:25,977 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:31:25,978 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:31:25,977 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:31:25,978 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:31:25,979 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710685979
2022-01-20T15:31:25,979 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710685979
2022-01-20T15:31:25,979 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:31:25,987 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:31:26,266 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:31:26,267 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:31:26,266 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:31:26,267 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:31:26,269 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:31:26,269 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:31:26,269 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:31:26,271 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:31:26,272 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:31:26,272 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:31:26,272 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:31:26,274 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:31:26,274 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:31:26,274 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:31:26,276 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:31:26,276 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:31:26,276 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:31:26,277 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:31:26,277 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:31:26,277 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:31:26,278 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:31:26,278 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:31:26,278 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:31:26,279 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T15:31:26,279 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:31:26,279 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:31:26,281 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:31:26,279 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:31:26,279 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T15:31:26,281 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:32:00,290 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:32:00,290 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:32:01,336 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:32:01,337 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]13764
2022-01-20T15:32:01,338 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:32:01,338 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:32:01,338 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:32:01,338 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:32:01,338 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:32:01,338 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:32:01,340 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710721340
2022-01-20T15:32:01,340 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:32:01,340 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710721340
2022-01-20T15:32:01,347 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:32:01,618 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:32:01,618 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:32:01,618 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:32:01,618 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:32:01,619 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:32:01,619 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:32:01,619 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:32:01,619 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:32:01,619 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:32:01,620 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:32:01,619 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:32:01,621 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:32:01,620 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:32:01,621 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:32:01,621 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:32:01,621 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:32:01,621 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:32:01,622 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:32:01,621 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:32:01,622 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:32:01,623 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:32:01,622 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:32:01,623 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:32:01,623 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T15:32:01,623 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:32:01,624 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:32:01,623 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T15:32:01,624 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:32:01,624 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:32:01,624 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:32:05,784 [INFO ] nioEventLoopGroup-3-2 ACCESS_LOG - /127.0.0.1:49387 "GET /models/nice HTTP/1.1" 200 52
2022-01-20T15:32:05,785 [INFO ] nioEventLoopGroup-3-2 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T15:32:56,640 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:32:56,640 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:32:57,706 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:32:57,707 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]18752
2022-01-20T15:32:57,708 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:32:57,708 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:32:57,708 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:32:57,709 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:32:57,708 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:32:57,709 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:32:57,711 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710777711
2022-01-20T15:32:57,711 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:32:57,711 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710777711
2022-01-20T15:32:57,718 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:32:57,988 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:32:57,989 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:32:57,988 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:32:57,989 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:32:57,990 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:32:57,989 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:32:57,990 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:32:57,990 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:32:57,990 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:32:57,990 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:32:57,991 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:32:57,991 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:32:57,991 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:32:57,992 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:32:57,991 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:32:57,992 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:32:57,992 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:32:57,992 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:32:57,992 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:32:57,993 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:32:57,993 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:32:57,993 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:32:57,994 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T15:32:57,994 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:32:57,994 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:32:57,994 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T15:32:57,995 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:32:57,994 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:32:57,995 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:34:27,010 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:34:27,010 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:34:28,040 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:34:28,040 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]28372
2022-01-20T15:34:28,041 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:34:28,041 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:34:28,041 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:34:28,041 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:34:28,042 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:34:28,042 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:34:28,043 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710868043
2022-01-20T15:34:28,043 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642710868043
2022-01-20T15:34:28,043 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:34:28,054 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:34:28,321 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:34:28,321 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:34:28,321 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:34:28,321 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:34:28,322 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:34:28,322 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:34:28,322 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:34:28,323 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:34:28,323 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:34:28,323 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:34:28,324 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:34:28,323 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:34:28,324 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:34:28,324 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:34:28,324 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:34:28,324 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:34:28,325 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:34:28,325 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:34:28,325 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:34:28,326 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:34:28,326 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:34:28,326 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:34:28,326 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2022-01-20T15:34:28,326 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:34:28,327 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:34:28,326 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2022-01-20T15:34:28,327 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:34:28,327 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:34:28,327 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:36:52,335 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:36:52,335 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:36:53,366 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:36:53,366 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]6016
2022-01-20T15:36:53,367 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:36:53,367 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:36:53,367 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:36:53,367 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:36:53,367 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:36:53,367 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:36:53,369 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642711013369
2022-01-20T15:36:53,369 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:36:53,369 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642711013369
2022-01-20T15:36:53,378 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:36:53,645 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:36:53,645 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:36:53,645 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:36:53,645 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:36:53,646 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:36:53,646 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:36:53,646 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:36:53,647 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:36:53,646 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:36:53,647 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:36:53,648 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:36:53,647 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:36:53,648 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:36:53,648 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:36:53,648 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:36:53,648 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:36:53,649 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:36:53,649 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:36:53,649 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:36:53,650 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:36:53,649 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:36:53,650 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:36:53,650 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 233 seconds.
2022-01-20T15:36:53,650 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:36:53,651 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:36:53,650 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 233 seconds.
2022-01-20T15:36:53,651 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:36:53,651 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:36:53,651 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:40:46,658 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:40:46,658 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:40:47,709 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:40:47,710 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]11236
2022-01-20T15:40:47,710 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:40:47,710 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:40:47,710 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:40:47,711 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:40:47,711 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:40:47,711 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:40:47,713 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642711247713
2022-01-20T15:40:47,713 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:40:47,713 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642711247713
2022-01-20T15:40:47,735 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:40:48,008 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:40:48,008 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:40:48,008 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:40:48,008 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:40:48,010 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:40:48,009 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:40:48,010 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:40:48,010 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:40:48,010 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:40:48,010 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:40:48,011 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:40:48,010 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:40:48,011 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:40:48,012 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:40:48,011 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:40:48,012 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:40:48,012 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:40:48,012 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:40:48,012 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:40:48,013 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:40:48,013 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:40:48,013 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:40:48,014 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 377 seconds.
2022-01-20T15:40:48,013 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:40:48,014 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:40:48,014 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 377 seconds.
2022-01-20T15:40:48,014 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:40:48,015 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:40:48,015 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:47:05,031 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:47:05,031 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:47:06,068 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:47:06,069 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]10216
2022-01-20T15:47:06,069 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:47:06,069 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:47:06,069 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:47:06,070 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:47:06,070 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:47:06,070 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:47:06,072 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642711626072
2022-01-20T15:47:06,072 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:47:06,072 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642711626072
2022-01-20T15:47:06,086 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:47:06,354 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:47:06,354 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:47:06,354 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:47:06,354 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:47:06,355 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:47:06,355 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:47:06,355 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:47:06,356 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:47:06,356 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:47:06,356 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:47:06,357 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:47:06,356 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:47:06,357 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:47:06,357 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:47:06,357 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:47:06,357 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:47:06,358 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:47:06,358 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:47:06,358 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:47:06,359 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:47:06,359 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:47:06,359 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:47:06,360 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 610 seconds.
2022-01-20T15:47:06,359 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:47:06,360 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:47:06,360 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:47:06,360 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 610 seconds.
2022-01-20T15:47:06,360 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:47:06,360 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:10,666 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T15:59:10,666 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T15:59:10,785 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: c:\users\adib\anaconda3\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice=nice-distilbertv2.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T15:59:10,785 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: c:\users\adib\anaconda3\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice=nice-distilbertv2.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T15:59:10,789 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T15:59:10,789 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T15:59:10,801 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-distilbertv2.mar
2022-01-20T15:59:10,801 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-distilbertv2.mar
2022-01-20T15:59:14,226 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice
2022-01-20T15:59:14,226 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice
2022-01-20T15:59:14,227 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:59:14,227 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice
2022-01-20T15:59:14,227 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice loaded.
2022-01-20T15:59:14,227 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice loaded.
2022-01-20T15:59:14,228 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice, count: 1
2022-01-20T15:59:14,228 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice, count: 1
2022-01-20T15:59:14,233 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:14,233 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:14,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T15:59:14,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T15:59:14,291 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T15:59:14,291 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T15:59:14,292 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T15:59:14,292 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T15:59:14,293 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T15:59:14,293 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T15:59:14,293 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T15:59:14,293 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T15:59:14,294 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T15:59:14,294 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T15:59:14,421 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T15:59:14,421 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T15:59:14,503 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642712354
2022-01-20T15:59:14,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:85.88510131835938|#Level:Host|#hostname:MeshifyC,timestamp:1642712354
2022-01-20T15:59:14,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:844.5527114868164|#Level:Host|#hostname:MeshifyC,timestamp:1642712354
2022-01-20T15:59:14,505 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:90.8|#Level:Host|#hostname:MeshifyC,timestamp:1642712354
2022-01-20T15:59:14,505 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21105.65234375|#Level:Host|#hostname:MeshifyC,timestamp:1642712354
2022-01-20T15:59:14,505 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11588.19140625|#Level:Host|#hostname:MeshifyC,timestamp:1642712354
2022-01-20T15:59:14,505 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:35.4|#Level:Host|#hostname:MeshifyC,timestamp:1642712354
2022-01-20T15:59:15,276 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:59:15,277 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]14176
2022-01-20T15:59:15,277 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:59:15,277 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change null -> WORKER_STARTED
2022-01-20T15:59:15,277 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:59:15,277 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change null -> WORKER_STARTED
2022-01-20T15:59:15,280 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:15,280 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:15,286 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:59:15,287 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712355287
2022-01-20T15:59:15,287 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712355287
2022-01-20T15:59:15,302 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:59:15,574 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:59:15,574 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:59:15,575 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:59:15,575 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:15,575 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:59:15,575 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:15,576 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:15,575 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:59:15,576 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:15,576 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:59:15,577 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:59:15,577 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:59:15,577 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:59:15,578 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T15:59:15,578 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-01-20T15:59:15,578 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-20T15:59:15,579 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-01-20T15:59:15,579 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-01-20T15:59:15,579 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\b4cd040f0bfa40e59a3836b47a158455\nice-distilbertv2-handler.py", line 108, in handle
2022-01-20T15:59:15,580 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     raise e
2022-01-20T15:59:15,580 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\b4cd040f0bfa40e59a3836b47a158455\nice-distilbertv2-handler.py", line 97, in handle
2022-01-20T15:59:15,580 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-01-20T15:59:15,581 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\b4cd040f0bfa40e59a3836b47a158455\nice-distilbertv2-handler.py", line 31, in initialize
2022-01-20T15:59:15,581 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-01-20T15:59:15,581 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 396, in from_pretrained
2022-01-20T15:59:15,581 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2022-01-20T15:59:15,582 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\models\auto\configuration_auto.py", line 558, in from_pretrained
2022-01-20T15:59:15,582 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2022-01-20T15:59:15,576 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:15,576 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:15,583 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:15,583 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\configuration_utils.py", line 550, in get_config_dict
2022-01-20T15:59:15,583 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:15,584 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:15,583 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     resolved_config_file = cached_path(
2022-01-20T15:59:15,584 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:15,584 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:15,584 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\transformers\file_utils.py", line 1509, in cached_path
2022-01-20T15:59:15,584 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:15,585 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:15,585 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     raise ValueError(f"unable to parse {url_or_filename} as a URL or as a local path")
2022-01-20T15:59:15,585 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:15,585 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - ValueError: unable to parse C:\Users\adib\AppData\Local\Temp\models\b4cd040f0bfa40e59a3836b47a158455\config.json as a URL or as a local path
2022-01-20T15:59:15,586 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:59:15,586 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:15,586 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:15,586 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:59:15,586 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:15,586 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:16,602 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:16,602 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:17,620 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:59:17,620 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]28400
2022-01-20T15:59:17,621 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:17,621 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:59:17,621 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:17,622 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:17,621 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:59:17,622 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:17,623 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712357623
2022-01-20T15:59:17,623 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712357623
2022-01-20T15:59:17,623 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:59:17,629 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:59:17,893 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:59:17,893 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:17,893 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:59:17,893 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:17,894 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:17,894 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:59:17,894 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:17,895 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:17,894 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:59:17,895 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:17,895 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:17,895 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:59:17,895 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:17,896 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:17,896 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:59:17,896 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:17,897 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:17,896 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:59:17,897 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:17,898 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:17,897 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:59:17,898 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:17,898 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:59:17,898 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:59:17,898 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:17,898 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T15:59:17,899 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:17,898 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:17,899 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:18,900 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:18,900 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:19,912 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:59:19,913 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]28168
2022-01-20T15:59:19,913 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:19,913 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:59:19,913 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:19,914 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:19,914 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:59:19,914 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:19,915 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712359915
2022-01-20T15:59:19,915 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:59:19,915 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712359915
2022-01-20T15:59:19,922 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:59:20,190 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:59:20,190 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:20,190 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:59:20,190 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:20,191 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:20,191 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:59:20,191 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:20,192 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:20,191 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:59:20,192 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:20,192 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:20,192 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:59:20,192 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:20,193 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:20,192 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:59:20,193 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:20,193 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:20,193 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:59:20,193 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:20,194 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:20,194 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:59:20,194 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:20,195 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T15:59:20,195 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:59:20,195 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:20,195 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T15:59:20,196 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:20,195 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:20,196 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:22,200 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:22,200 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:23,227 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:59:23,227 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]11364
2022-01-20T15:59:23,228 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:23,228 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:59:23,228 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:23,229 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:23,228 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:59:23,229 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:23,230 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712363230
2022-01-20T15:59:23,230 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:59:23,230 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712363230
2022-01-20T15:59:23,237 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:59:23,502 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:59:23,502 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:23,502 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:59:23,502 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:23,503 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:23,503 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:59:23,503 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:23,503 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:23,503 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:59:23,503 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:23,504 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:23,504 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:59:23,504 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:23,505 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:23,504 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:59:23,505 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:23,505 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:23,505 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:59:23,505 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:23,506 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:23,506 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:59:23,506 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:23,507 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T15:59:23,506 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:59:23,507 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:23,507 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T15:59:23,507 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:23,507 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:23,507 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:26,513 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:26,513 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:27,532 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:59:27,532 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]6416
2022-01-20T15:59:27,533 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:27,533 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:59:27,533 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:27,533 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:59:27,534 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:27,534 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:27,535 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712367535
2022-01-20T15:59:27,535 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:59:27,535 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712367535
2022-01-20T15:59:27,541 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:59:27,808 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:59:27,809 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:27,809 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:59:27,809 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:27,810 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:27,810 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:59:27,810 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:27,811 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:27,810 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:59:27,811 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:27,811 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:27,811 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:59:27,811 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:27,812 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:27,812 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:59:27,812 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:27,813 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:27,812 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:59:27,813 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:27,813 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:27,813 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:59:27,813 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:27,814 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T15:59:27,814 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:59:27,814 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:27,814 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T15:59:27,815 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:27,814 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:27,815 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:32,816 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:32,816 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:33,852 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:59:33,853 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]2496
2022-01-20T15:59:33,854 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:33,854 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:59:33,854 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:33,854 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:33,854 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:59:33,854 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:33,856 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712373856
2022-01-20T15:59:33,856 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:59:33,856 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712373856
2022-01-20T15:59:33,863 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:59:34,135 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:59:34,135 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:34,135 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:59:34,135 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:34,137 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:34,136 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:59:34,137 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:34,139 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:34,138 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:59:34,139 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:34,140 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:34,139 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:59:34,140 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:34,142 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:34,141 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:59:34,142 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:34,144 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:34,143 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:59:34,144 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:34,145 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:34,144 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:59:34,145 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:34,146 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T15:59:34,146 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:34,145 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:59:34,148 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:34,146 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:34,146 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T15:59:34,148 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:42,157 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:42,157 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:43,189 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T15:59:43,190 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]14604
2022-01-20T15:59:43,191 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:43,191 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T15:59:43,191 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T15:59:43,191 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:43,191 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T15:59:43,191 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T15:59:43,193 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712383193
2022-01-20T15:59:43,193 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T15:59:43,193 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712383193
2022-01-20T15:59:43,200 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T15:59:43,467 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T15:59:43,467 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:43,467 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T15:59:43,467 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T15:59:43,468 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:43,467 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T15:59:43,468 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T15:59:43,468 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:43,468 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T15:59:43,468 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T15:59:43,469 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:43,469 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T15:59:43,469 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T15:59:43,470 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:43,469 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T15:59:43,470 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T15:59:43,470 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:43,470 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T15:59:43,470 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T15:59:43,471 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:43,471 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T15:59:43,471 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T15:59:43,472 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T15:59:43,471 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T15:59:43,472 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:43,472 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T15:59:43,472 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:43,472 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T15:59:43,472 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T15:59:56,477 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T15:59:56,477 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T16:00:05,877 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T16:00:05,877 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]16512
2022-01-20T16:00:05,879 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:00:05,879 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T16:00:05,879 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:00:05,879 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:00:05,879 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T16:00:05,879 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:00:05,881 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712405881
2022-01-20T16:00:05,881 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T16:00:05,881 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712405881
2022-01-20T16:00:05,888 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T16:00:06,152 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T16:00:06,152 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:00:06,152 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T16:00:06,152 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:00:06,153 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:00:06,153 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T16:00:06,153 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:00:06,154 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:00:06,153 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T16:00:06,154 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:00:06,154 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:00:06,154 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T16:00:06,154 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:00:06,155 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:00:06,155 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T16:00:06,155 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:00:06,155 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:00:06,155 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T16:00:06,155 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:00:06,156 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:00:06,156 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T16:00:06,156 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:00:06,157 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T16:00:06,157 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T16:00:06,157 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:00:06,157 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T16:00:06,158 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T16:00:06,157 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:00:06,158 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T16:00:14,513 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642712414
2022-01-20T16:00:14,514 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:85.88948059082031|#Level:Host|#hostname:MeshifyC,timestamp:1642712414
2022-01-20T16:00:14,515 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:844.5483322143555|#Level:Host|#hostname:MeshifyC,timestamp:1642712414
2022-01-20T16:00:14,515 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:90.8|#Level:Host|#hostname:MeshifyC,timestamp:1642712414
2022-01-20T16:00:14,515 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:21077.55078125|#Level:Host|#hostname:MeshifyC,timestamp:1642712414
2022-01-20T16:00:14,515 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:11616.29296875|#Level:Host|#hostname:MeshifyC,timestamp:1642712414
2022-01-20T16:00:14,516 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:35.5|#Level:Host|#hostname:MeshifyC,timestamp:1642712414
2022-01-20T16:00:27,161 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T16:00:27,161 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T16:00:28,231 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T16:00:28,231 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]22284
2022-01-20T16:00:28,232 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:00:28,232 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T16:00:28,232 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:00:28,233 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:00:28,232 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T16:00:28,233 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:00:28,234 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712428234
2022-01-20T16:00:28,234 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T16:00:28,234 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712428234
2022-01-20T16:00:28,243 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T16:00:28,512 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T16:00:28,512 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:00:28,512 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T16:00:28,512 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:00:28,513 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:00:28,513 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T16:00:28,513 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:00:28,514 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:00:28,514 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T16:00:28,514 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:00:28,515 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:00:28,514 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T16:00:28,515 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:00:28,515 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:00:28,515 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T16:00:28,515 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:00:28,516 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:00:28,516 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T16:00:28,516 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:00:28,517 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:00:28,516 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T16:00:28,517 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:00:28,517 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T16:00:28,517 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T16:00:28,517 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:00:28,517 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T16:00:28,518 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T16:00:28,517 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:00:28,518 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T16:01:02,524 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T16:01:02,524 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T16:01:03,548 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T16:01:03,548 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]24872
2022-01-20T16:01:03,548 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:01:03,548 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T16:01:03,548 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:01:03,548 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T16:01:03,548 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:01:03,548 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:01:03,549 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712463549
2022-01-20T16:01:03,549 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T16:01:03,549 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712463549
2022-01-20T16:01:03,556 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T16:01:03,822 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T16:01:03,822 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T16:01:03,822 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:01:03,822 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T16:01:03,822 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:01:03,822 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T16:01:03,822 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:01:03,822 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:01:03,822 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T16:01:03,822 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T16:01:03,822 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:01:03,822 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:01:03,823 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:01:03,822 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T16:01:03,823 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:01:03,823 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:01:03,823 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T16:01:03,823 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:01:03,824 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:01:03,824 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T16:01:03,824 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:01:03,825 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:01:03,824 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T16:01:03,825 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:01:03,825 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T16:01:03,825 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "c:\users\adib\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-01-20T16:01:03,826 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:01:03,826 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T16:01:03,825 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T16:01:03,826 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:01:03,826 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T16:01:58,835 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T16:01:58,835 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\adib\anaconda3\python.exe, C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T16:01:59,871 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T16:01:59,872 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - [PID]8516
2022-01-20T16:01:59,873 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:01:59,873 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T16:01:59,873 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T16:01:59,873 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:01:59,873 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Python runtime: 3.8.8
2022-01-20T16:01:59,873 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T16:01:59,875 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712519875
2022-01-20T16:01:59,875 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642712519875
2022-01-20T16:01:59,875 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T16:01:59,882 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - model_name: nice, batchSize: 1
2022-01-20T16:02:00,164 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T16:02:00,164 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:02:00,164 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T16:02:00,164 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T16:02:00,165 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:02:00,165 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T16:02:00,165 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T16:02:00,166 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:02:00,165 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T16:02:00,166 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T16:02:00,166 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:02:00,166 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T16:02:00,166 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice, error: Worker died.
2022-01-20T16:02:00,167 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:02:00,166 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T16:02:00,167 [DEBUG] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T16:02:00,168 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:02:00,167 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T16:02:00,168 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stderr
2022-01-20T16:02:00,168 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:02:00,168 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T16:02:00,168 [WARN ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_1.0-stdout
2022-01-20T16:02:00,169 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T16:02:00,169 [INFO ] W-9000-nice_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T16:02:00,169 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:02:00,169 [INFO ] W-9000-nice_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T16:02:00,170 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T16:02:00,169 [INFO ] W-9000-nice_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stdout
2022-01-20T16:02:00,170 [INFO ] W-9000-nice_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_1.0-stderr
2022-01-20T17:48:06,306 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T17:48:06,306 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T17:48:06,424 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice_dbert=nice-dbert.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T17:48:06,424 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice_dbert=nice-dbert.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T17:48:06,428 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T17:48:06,428 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T17:48:06,439 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-dbert.mar
2022-01-20T17:48:06,439 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-dbert.mar
2022-01-20T17:48:09,944 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice_dbert
2022-01-20T17:48:09,944 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice_dbert
2022-01-20T17:48:09,944 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice_dbert
2022-01-20T17:48:09,944 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice_dbert
2022-01-20T17:48:09,945 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice_dbert loaded.
2022-01-20T17:48:09,945 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice_dbert loaded.
2022-01-20T17:48:09,945 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice_dbert, count: 1
2022-01-20T17:48:09,945 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice_dbert, count: 1
2022-01-20T17:48:09,951 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:09,951 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T17:48:09,951 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T17:48:09,951 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:10,009 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T17:48:10,009 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T17:48:10,009 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T17:48:10,009 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T17:48:10,010 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T17:48:10,010 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T17:48:10,010 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T17:48:10,010 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T17:48:10,011 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T17:48:10,011 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T17:48:10,137 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T17:48:10,137 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T17:48:10,233 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642718890
2022-01-20T17:48:10,233 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:84.8934326171875|#Level:Host|#hostname:MeshifyC,timestamp:1642718890
2022-01-20T17:48:10,234 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:845.5443801879883|#Level:Host|#hostname:MeshifyC,timestamp:1642718890
2022-01-20T17:48:10,234 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:90.9|#Level:Host|#hostname:MeshifyC,timestamp:1642718890
2022-01-20T17:48:10,235 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20819.125|#Level:Host|#hostname:MeshifyC,timestamp:1642718890
2022-01-20T17:48:10,235 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11874.71875|#Level:Host|#hostname:MeshifyC,timestamp:1642718890
2022-01-20T17:48:10,235 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:36.3|#Level:Host|#hostname:MeshifyC,timestamp:1642718890
2022-01-20T17:48:11,085 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:11,086 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]1980
2022-01-20T17:48:11,087 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:11,087 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change null -> WORKER_STARTED
2022-01-20T17:48:11,087 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:11,087 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change null -> WORKER_STARTED
2022-01-20T17:48:11,089 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:11,089 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:11,095 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:11,097 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718891097
2022-01-20T17:48:11,097 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718891097
2022-01-20T17:48:11,113 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:11,119 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:11,119 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:11,119 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:11,120 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:11,120 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:11,120 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:11,120 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:11,120 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:11,120 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:11,121 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:11,121 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:11,122 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:11,122 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:11,122 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T17:48:11,122 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-20T17:48:11,123 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-20T17:48:11,123 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-20T17:48:11,123 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-20T17:48:11,124 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\importlib\__init__.py", line 127, in import_module
2022-01-20T17:48:11,124 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-20T17:48:11,124 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
2022-01-20T17:48:11,125 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
2022-01-20T17:48:11,125 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
2022-01-20T17:48:11,125 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
2022-01-20T17:48:11,125 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 839, in exec_module
2022-01-20T17:48:11,126 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 976, in get_code
2022-01-20T17:48:11,126 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
2022-01-20T17:48:11,126 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2022-01-20T17:48:11,121 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:11,121 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:11,127 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:11,127 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\7f69aa93578a47a484b59e5a0e8965f2\handler.py", line 1
2022-01-20T17:48:11,127 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:11,128 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:11,128 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     {\rtf1}
2022-01-20T17:48:11,128 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:11,128 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:11,128 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -           ^
2022-01-20T17:48:11,128 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:11,131 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:11,129 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - SyntaxError: unexpected character after line continuation character
2022-01-20T17:48:11,131 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:11,131 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:11,131 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:11,132 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T17:48:11,131 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:11,131 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:11,132 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T17:48:12,136 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:12,136 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:13,194 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:13,195 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]27728
2022-01-20T17:48:13,196 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:13,196 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:13,196 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:13,196 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:13,196 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:13,196 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:13,198 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718893198
2022-01-20T17:48:13,198 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718893198
2022-01-20T17:48:13,198 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:13,206 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:13,207 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:13,207 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:13,207 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:13,207 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:13,208 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:13,208 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:13,208 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:13,209 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:13,209 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:13,209 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:13,210 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:13,209 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:13,210 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:13,210 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:13,210 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:13,210 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:13,211 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:13,210 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:13,211 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:13,211 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:13,211 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:13,211 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:13,212 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T17:48:13,212 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:13,212 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:13,212 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T17:48:13,212 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:13,213 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:13,213 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:14,223 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:14,223 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:15,278 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:15,279 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]26468
2022-01-20T17:48:15,280 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:15,280 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:15,280 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:15,280 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:15,280 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:15,280 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:15,282 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718895282
2022-01-20T17:48:15,282 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:15,282 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718895282
2022-01-20T17:48:15,290 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:15,291 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:15,291 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:15,291 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:15,291 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:15,292 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:15,292 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:15,292 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:15,292 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:15,292 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:15,292 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:15,293 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:15,293 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:15,293 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:15,294 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:15,293 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:15,294 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:15,295 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:15,295 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:15,295 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:15,296 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:15,296 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:15,296 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:15,297 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T17:48:15,296 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:15,297 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:15,297 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T17:48:15,297 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:15,298 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:15,298 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:17,304 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:17,304 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:18,354 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:18,354 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]3796
2022-01-20T17:48:18,355 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:18,355 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:18,355 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:18,356 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:18,355 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:18,356 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:18,357 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718898357
2022-01-20T17:48:18,357 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718898357
2022-01-20T17:48:18,357 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:18,365 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:18,366 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:18,366 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:18,366 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:18,366 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:18,367 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:18,366 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:18,367 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:18,367 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:18,367 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:18,368 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:18,367 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:18,368 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:18,368 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:18,368 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:18,369 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:18,368 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:18,369 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:18,369 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:18,369 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:18,369 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:18,370 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:18,370 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:18,370 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:18,371 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T17:48:18,371 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T17:48:18,371 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:18,371 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T17:48:18,371 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:18,372 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:18,372 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:21,378 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:21,378 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:22,432 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:22,433 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]24772
2022-01-20T17:48:22,434 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:22,434 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:22,434 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:22,434 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:22,434 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:22,434 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:22,436 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718902436
2022-01-20T17:48:22,436 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718902436
2022-01-20T17:48:22,436 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:22,443 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:22,445 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:22,445 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:22,445 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:22,445 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:22,445 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:22,445 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:22,445 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:22,446 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:22,445 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:22,446 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:22,447 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:22,446 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:22,447 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:22,447 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:22,447 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:22,447 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:22,448 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:22,447 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:22,448 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:22,448 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:22,448 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:22,448 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:22,449 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T17:48:22,449 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:22,449 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:22,449 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T17:48:22,449 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:22,450 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:22,450 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:27,463 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:27,463 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:28,526 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:28,527 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]11696
2022-01-20T17:48:28,528 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:28,528 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:28,528 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:28,528 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:28,528 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:28,528 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:28,530 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718908530
2022-01-20T17:48:28,530 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718908530
2022-01-20T17:48:28,530 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:28,538 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:28,539 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:28,539 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:28,539 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:28,539 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:28,540 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:28,540 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:28,540 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:28,541 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:28,540 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:28,541 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:28,541 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:28,542 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:28,541 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:28,542 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:28,542 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:28,542 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:28,542 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:28,543 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:28,542 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:28,543 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:28,543 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:28,543 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:28,543 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:28,544 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T17:48:28,544 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T17:48:28,544 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:28,544 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T17:48:28,544 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:28,545 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:28,545 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:29,466 [INFO ] W-9000-nice_dbert_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:49194 "GET /ping HTTP/1.1" 200 4
2022-01-20T17:48:29,466 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T17:48:36,546 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:36,546 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:37,614 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:37,615 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]18568
2022-01-20T17:48:37,616 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:37,616 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:37,616 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:37,616 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:37,616 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:37,616 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:37,618 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718917618
2022-01-20T17:48:37,618 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:37,618 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718917618
2022-01-20T17:48:37,626 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:37,628 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:37,628 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:37,628 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:37,628 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:37,628 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:37,628 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:37,628 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:37,629 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:37,629 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:37,629 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:37,630 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:37,629 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:37,630 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:37,630 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:37,630 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:37,630 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:37,630 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:37,631 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:37,631 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:37,632 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:37,631 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:37,632 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:37,633 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T17:48:37,632 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:37,633 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:37,633 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:37,633 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T17:48:37,633 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:37,633 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:50,647 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:50,647 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T17:48:51,723 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T17:48:51,724 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]20036
2022-01-20T17:48:51,724 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:51,724 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T17:48:51,724 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T17:48:51,725 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:51,725 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T17:48:51,725 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T17:48:51,727 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718931726
2022-01-20T17:48:51,727 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642718931726
2022-01-20T17:48:51,727 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T17:48:51,735 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T17:48:51,736 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T17:48:51,736 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:51,736 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T17:48:51,736 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T17:48:51,737 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:51,736 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T17:48:51,737 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T17:48:51,737 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:51,737 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T17:48:51,737 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T17:48:51,738 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:51,738 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T17:48:51,738 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T17:48:51,739 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:51,738 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T17:48:51,739 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T17:48:51,739 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:51,739 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T17:48:51,739 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:51,740 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:51,740 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T17:48:51,740 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:51,741 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T17:48:51,741 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T17:48:51,741 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:51,741 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T17:48:51,742 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T17:48:51,741 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T17:48:51,742 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:24,834 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T18:18:24,834 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T18:18:24,954 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice_dbert=nice-dbert.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T18:18:24,954 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice_dbert=nice-dbert.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T18:18:24,958 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T18:18:24,958 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T18:18:24,970 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-dbert.mar
2022-01-20T18:18:24,970 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-dbert.mar
2022-01-20T18:18:28,463 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice_dbert
2022-01-20T18:18:28,463 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice_dbert
2022-01-20T18:18:28,463 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice_dbert
2022-01-20T18:18:28,463 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice_dbert
2022-01-20T18:18:28,464 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice_dbert loaded.
2022-01-20T18:18:28,464 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice_dbert loaded.
2022-01-20T18:18:28,464 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice_dbert, count: 1
2022-01-20T18:18:28,464 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice_dbert, count: 1
2022-01-20T18:18:28,470 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:28,470 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T18:18:28,470 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T18:18:28,470 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:28,528 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T18:18:28,528 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T18:18:28,528 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T18:18:28,528 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T18:18:28,530 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T18:18:28,530 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T18:18:28,530 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T18:18:28,530 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T18:18:28,530 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T18:18:28,530 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T18:18:28,656 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T18:18:28,656 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T18:18:28,748 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642720708
2022-01-20T18:18:28,748 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:84.28630828857422|#Level:Host|#hostname:MeshifyC,timestamp:1642720708
2022-01-20T18:18:28,749 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:846.1515045166016|#Level:Host|#hostname:MeshifyC,timestamp:1642720708
2022-01-20T18:18:28,749 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:90.9|#Level:Host|#hostname:MeshifyC,timestamp:1642720708
2022-01-20T18:18:28,750 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20138.30078125|#Level:Host|#hostname:MeshifyC,timestamp:1642720708
2022-01-20T18:18:28,750 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:12555.54296875|#Level:Host|#hostname:MeshifyC,timestamp:1642720708
2022-01-20T18:18:28,750 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:38.4|#Level:Host|#hostname:MeshifyC,timestamp:1642720708
2022-01-20T18:18:29,554 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:18:29,555 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]14468
2022-01-20T18:18:29,561 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:18:29,561 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change null -> WORKER_STARTED
2022-01-20T18:18:29,561 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change null -> WORKER_STARTED
2022-01-20T18:18:29,561 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:18:29,563 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:29,563 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:29,569 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:18:29,571 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720709571
2022-01-20T18:18:29,571 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720709571
2022-01-20T18:18:29,585 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:18:29,593 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:18:29,593 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:18:29,593 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:18:29,594 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:29,594 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:18:29,594 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:29,594 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:29,594 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:18:29,594 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:29,594 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:18:29,595 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:18:29,595 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:18:29,596 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:18:29,596 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T18:18:29,597 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-20T18:18:29,597 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-20T18:18:29,598 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 123, in _load_handler_file
2022-01-20T18:18:29,598 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-01-20T18:18:29,598 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\importlib\__init__.py", line 127, in import_module
2022-01-20T18:18:29,599 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-01-20T18:18:29,599 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
2022-01-20T18:18:29,599 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
2022-01-20T18:18:29,600 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
2022-01-20T18:18:29,600 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
2022-01-20T18:18:29,600 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 839, in exec_module
2022-01-20T18:18:29,601 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 976, in get_code
2022-01-20T18:18:29,601 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
2022-01-20T18:18:29,595 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:29,601 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2022-01-20T18:18:29,595 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:29,602 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:29,602 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\AppData\Local\Temp\models\b823b34ccecd437aa48723580cff6aab\handler.py", line 1
2022-01-20T18:18:29,602 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:29,604 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:29,603 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     {\rtf1}
2022-01-20T18:18:29,604 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:29,604 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:29,604 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -           ^
2022-01-20T18:18:29,604 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:29,605 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:29,605 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - SyntaxError: unexpected character after line continuation character
2022-01-20T18:18:29,605 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:29,606 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T18:18:29,606 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T18:18:29,607 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:29,607 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:29,607 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:29,607 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:30,617 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:30,617 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:31,673 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:18:31,673 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]28032
2022-01-20T18:18:31,674 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:31,674 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:18:31,674 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:31,674 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:18:31,675 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:31,675 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:31,676 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720711676
2022-01-20T18:18:31,676 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720711676
2022-01-20T18:18:31,676 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:18:31,682 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:18:31,684 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:18:31,684 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:31,684 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:18:31,684 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:31,684 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:18:31,684 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:31,685 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:18:31,684 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:31,685 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:18:31,685 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:31,685 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:31,686 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:31,685 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:18:31,686 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:31,686 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:31,686 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:18:31,686 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:31,687 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:31,687 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:18:31,687 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:31,688 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:31,688 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:18:31,688 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:31,688 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T18:18:31,688 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T18:18:31,688 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:31,688 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-01-20T18:18:31,688 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:31,689 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:31,689 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:32,693 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:32,693 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:33,755 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:18:33,755 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]1800
2022-01-20T18:18:33,756 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:33,756 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:18:33,756 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:33,757 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:33,756 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:18:33,757 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:33,758 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720713758
2022-01-20T18:18:33,758 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:18:33,758 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720713758
2022-01-20T18:18:33,765 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:18:33,766 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:18:33,766 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:33,766 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:18:33,766 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:33,767 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:33,767 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:18:33,767 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:33,767 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:33,767 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:18:33,767 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:33,768 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:33,768 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:18:33,768 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:33,769 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:33,768 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:18:33,769 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:33,769 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:33,769 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:18:33,769 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:33,770 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:33,770 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:18:33,770 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:33,771 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T18:18:33,770 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:18:33,771 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:33,771 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-01-20T18:18:33,772 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:33,771 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:33,772 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:35,783 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:35,783 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:36,841 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:18:36,841 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]932
2022-01-20T18:18:36,842 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:36,842 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:18:36,842 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:36,843 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:36,842 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:18:36,843 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:36,844 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720716844
2022-01-20T18:18:36,844 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720716844
2022-01-20T18:18:36,844 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:18:36,850 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:18:36,852 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:18:36,852 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:36,852 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:18:36,852 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:36,852 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:36,852 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:18:36,852 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:36,853 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:36,853 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:18:36,853 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:36,854 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:36,853 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:18:36,854 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:36,854 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:36,854 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:18:36,854 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:36,855 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:36,854 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:18:36,855 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:36,856 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:36,855 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:18:36,856 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:36,856 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T18:18:36,856 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:18:36,856 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:36,856 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-01-20T18:18:36,856 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:36,857 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:36,857 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:39,860 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:39,860 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:40,929 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:18:40,929 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]20568
2022-01-20T18:18:40,929 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:40,929 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:18:40,929 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:40,929 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:18:40,929 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:40,929 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:40,930 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720720930
2022-01-20T18:18:40,930 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:18:40,930 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720720930
2022-01-20T18:18:40,937 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:18:40,938 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:18:40,938 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:18:40,938 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:40,938 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:18:40,938 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:18:40,938 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:40,939 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:18:40,939 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:40,939 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:40,939 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:18:40,939 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:40,939 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:18:40,939 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:40,939 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:40,939 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:18:40,939 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:40,940 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:40,940 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:18:40,940 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:40,944 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:40,947 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:40,943 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T18:18:40,947 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:40,944 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:40,951 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:40,948 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-20T18:18:40,951 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:40,955 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T18:18:40,952 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-01-20T18:18:40,956 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:40,955 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-01-20T18:18:40,956 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:45,968 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:45,968 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:47,032 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:18:47,033 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]6032
2022-01-20T18:18:47,034 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:47,034 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:18:47,034 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:47,035 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:47,035 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:18:47,035 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:47,040 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720727040
2022-01-20T18:18:47,040 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:18:47,040 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720727040
2022-01-20T18:18:47,047 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:18:47,048 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:18:47,048 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:47,048 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:18:47,048 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:47,051 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:47,048 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:18:47,051 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:47,052 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:18:47,052 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:47,052 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:18:47,052 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:47,053 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:47,053 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:18:47,053 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:47,057 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:47,056 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:18:47,057 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:47,057 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:18:47,057 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:47,057 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:18:47,057 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:47,060 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:47,060 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T18:18:47,060 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:47,060 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:47,060 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T18:18:47,060 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\lib\site-packages\ts\model_loader.py", line 83, in load
2022-01-20T18:18:47,060 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-01-20T18:18:47,062 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:47,060 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:47,062 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:55,075 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:55,075 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:18:56,147 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:18:56,148 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]28004
2022-01-20T18:18:56,149 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:56,149 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:18:56,149 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:18:56,150 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:56,149 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:18:56,150 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:18:56,152 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720736152
2022-01-20T18:18:56,152 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720736152
2022-01-20T18:18:56,152 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:18:56,158 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:18:56,160 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:18:56,160 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:56,160 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:18:56,160 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:18:56,161 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:56,160 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:18:56,161 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:18:56,161 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:56,161 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:18:56,161 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:18:56,162 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:56,162 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:18:56,162 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:18:56,163 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:56,163 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:18:56,163 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:18:56,164 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:56,164 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:18:56,164 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:56,165 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:56,165 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:18:56,165 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:56,166 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T18:18:56,165 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:18:56,166 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:18:56,167 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:56,166 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-01-20T18:18:56,167 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:18:56,166 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:09,176 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:19:09,176 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:19:10,229 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:19:10,230 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]20932
2022-01-20T18:19:10,230 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:19:10,230 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:19:10,230 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:19:10,232 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:19:10,232 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:19:10,232 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:19:10,237 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720750237
2022-01-20T18:19:10,237 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720750237
2022-01-20T18:19:10,237 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:19:10,243 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:19:10,244 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:19:10,245 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:19:10,244 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:19:10,245 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:19:10,247 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:19:10,245 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:19:10,247 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:19:10,248 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:19:10,248 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:19:10,248 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:19:10,248 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:19:10,253 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:19:10,253 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:19:10,253 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:19:10,257 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:19:10,256 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:19:10,257 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:19:10,260 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:10,260 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:19:10,263 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:10,260 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:10,265 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:10,263 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:10,261 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:19:10,265 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:10,269 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T18:19:10,269 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-20T18:19:10,270 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:10,269 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-01-20T18:19:10,270 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:28,752 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642720768
2022-01-20T18:19:28,753 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:84.28764724731445|#Level:Host|#hostname:MeshifyC,timestamp:1642720768
2022-01-20T18:19:28,754 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:846.1501655578613|#Level:Host|#hostname:MeshifyC,timestamp:1642720768
2022-01-20T18:19:28,755 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:90.9|#Level:Host|#hostname:MeshifyC,timestamp:1642720768
2022-01-20T18:19:28,756 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20331.171875|#Level:Host|#hostname:MeshifyC,timestamp:1642720768
2022-01-20T18:19:28,759 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:12362.671875|#Level:Host|#hostname:MeshifyC,timestamp:1642720768
2022-01-20T18:19:28,760 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:37.8|#Level:Host|#hostname:MeshifyC,timestamp:1642720768
2022-01-20T18:19:31,283 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:19:31,283 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:19:32,340 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:19:32,340 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]17664
2022-01-20T18:19:32,341 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:19:32,341 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:19:32,341 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:19:32,343 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:19:32,342 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:19:32,343 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:19:32,347 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720772347
2022-01-20T18:19:32,347 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:19:32,347 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720772347
2022-01-20T18:19:32,354 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:19:32,355 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:19:32,355 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:19:32,355 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:19:32,355 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:19:32,358 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:19:32,356 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:19:32,358 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:19:32,359 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:19:32,358 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:19:32,359 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:19:32,360 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:19:32,359 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:19:32,360 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:19:32,363 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:19:32,360 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:19:32,363 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:19:32,368 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:32,363 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:19:32,371 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:32,368 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:32,373 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:32,371 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:19:32,370 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:19:32,373 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:32,375 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T18:19:32,375 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:19:32,375 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:19:32,375 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-01-20T18:19:32,375 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:20:06,379 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:20:06,379 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:20:07,427 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:20:07,428 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]3432
2022-01-20T18:20:07,429 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:20:07,428 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:20:07,429 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:20:07,432 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:20:07,432 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:20:07,432 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:20:07,434 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720807434
2022-01-20T18:20:07,434 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720807434
2022-01-20T18:20:07,434 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:20:07,440 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:20:07,442 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:20:07,442 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:20:07,442 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:20:07,442 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:20:07,442 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:20:07,445 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:20:07,445 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:20:07,445 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:20:07,445 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:20:07,445 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:20:07,446 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:20:07,445 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:20:07,446 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:20:07,448 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:20:07,446 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:20:07,448 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:20:07,449 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:20:07,448 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:20:07,452 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:20:07,449 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:20:07,453 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:20:07,452 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:20:07,450 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:20:07,453 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:20:07,457 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T18:20:07,457 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:20:07,457 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:20:07,457 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-01-20T18:20:07,457 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:21:02,467 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:21:02,467 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:21:03,519 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:21:03,519 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]17272
2022-01-20T18:21:03,520 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:21:03,520 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:21:03,520 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:21:03,521 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:21:03,520 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:21:03,521 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:21:03,523 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720863523
2022-01-20T18:21:03,523 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720863523
2022-01-20T18:21:03,523 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:21:03,529 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:21:03,536 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:21:03,537 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:21:03,537 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:21:03,537 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:21:03,537 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:21:03,537 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:21:03,537 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:21:03,538 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:21:03,538 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:21:03,538 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:21:03,539 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:21:03,539 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:21:03,539 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:21:03,540 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:21:03,540 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:21:03,540 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:21:03,541 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:21:03,540 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:21:03,541 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:21:03,542 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:21:03,541 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:21:03,542 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:21:03,542 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T18:21:03,542 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:21:03,543 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:21:03,543 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:21:03,542 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-01-20T18:21:03,543 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:21:03,543 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:22:32,546 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:22:32,546 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:22:33,597 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:22:33,598 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]27668
2022-01-20T18:22:33,598 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:22:33,598 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:22:33,598 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:22:33,600 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:22:33,598 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:22:33,600 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:22:33,603 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720953603
2022-01-20T18:22:33,603 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642720953603
2022-01-20T18:22:33,603 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:22:33,611 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:22:33,612 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:22:33,613 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:22:33,613 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:22:33,613 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:22:33,614 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:22:33,613 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:22:33,614 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:22:33,615 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:22:33,615 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:22:33,615 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:22:33,618 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:22:33,618 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:22:33,618 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:22:33,619 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:22:33,619 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:22:33,619 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:22:33,623 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:22:33,622 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:22:33,623 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:22:33,623 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:22:33,625 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:22:33,623 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:22:33,625 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:22:33,623 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:22:33,630 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2022-01-20T18:22:33,626 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:22:33,632 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:22:33,630 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2022-01-20T18:22:33,632 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:24:57,643 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:24:57,643 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:24:58,708 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:24:58,708 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]10528
2022-01-20T18:24:58,709 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:24:58,709 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:24:58,709 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-20T18:24:58,711 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:24:58,710 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:24:58,711 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:24:58,715 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642721098715
2022-01-20T18:24:58,715 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:24:58,715 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642721098715
2022-01-20T18:24:58,724 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:24:58,725 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend worker process died.
2022-01-20T18:24:58,725 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:24:58,725 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-20T18:24:58,725 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-01-20T18:24:58,726 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:24:58,726 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-01-20T18:24:58,726 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-20T18:24:58,727 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:24:58,727 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     worker.run_server()
2022-01-20T18:24:58,727 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:24:58,731 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:24:58,729 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-01-20T18:24:58,731 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nice_dbert, error: Worker died.
2022-01-20T18:24:58,735 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:24:58,731 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-20T18:24:58,735 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-20T18:24:58,736 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:24:58,735 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-01-20T18:24:58,738 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:24:58,736 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stderr
2022-01-20T18:24:58,739 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:24:58,738 [INFO ] W-9000-nice_dbert_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stderr
2022-01-20T18:24:58,736 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-20T18:24:58,739 [WARN ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-nice_dbert_1.0-stdout
2022-01-20T18:24:58,743 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 233 seconds.
2022-01-20T18:24:58,742 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -   File "C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py", line 95, in load_model
2022-01-20T18:24:58,743 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:24:58,743 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 233 seconds.
2022-01-20T18:24:58,743 [INFO ] W-9000-nice_dbert_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-nice_dbert_1.0-stdout
2022-01-20T18:28:51,746 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:33:49,502 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T18:33:49,502 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-20T18:33:49,607 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice_dbert=nice-dbert.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 12
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T18:33:49,607 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\adib\anaconda3\envs\ML\Lib\site-packages
Current directory: C:\Users\adib\Desktop\torchserve_local
Temp directory: C:\Users\adib\AppData\Local\Temp
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 8176 M
Python executable: C:\Users\adib\anaconda3\envs\ML\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\adib\Desktop\torchserve_local\model_store
Initial Models: nice_dbert=nice-dbert.mar
Log dir: C:\Users\adib\Desktop\torchserve_local\logs
Metrics dir: C:\Users\adib\Desktop\torchserve_local\logs
Netty threads: 12
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\adib\Desktop\torchserve_local\model_store
Model config: N/A
2022-01-20T18:33:49,611 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T18:33:49,611 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-20T18:33:49,623 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-dbert.mar
2022-01-20T18:33:49,623 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: nice-dbert.mar
2022-01-20T18:33:53,036 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice_dbert
2022-01-20T18:33:53,036 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nice_dbert
2022-01-20T18:33:53,037 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice_dbert
2022-01-20T18:33:53,037 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nice_dbert
2022-01-20T18:33:53,037 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice_dbert loaded.
2022-01-20T18:33:53,037 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nice_dbert loaded.
2022-01-20T18:33:53,038 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice_dbert, count: 1
2022-01-20T18:33:53,038 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nice_dbert, count: 1
2022-01-20T18:33:53,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T18:33:53,044 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:33:53,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-01-20T18:33:53,044 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\adib\anaconda3\envs\ML\python.exe, C:\Users\adib\anaconda3\envs\ML\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-01-20T18:33:53,099 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T18:33:53,099 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2022-01-20T18:33:53,099 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T18:33:53,099 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-01-20T18:33:53,100 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T18:33:53,100 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2022-01-20T18:33:53,100 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T18:33:53,100 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-01-20T18:33:53,101 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T18:33:53,101 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2022-01-20T18:33:53,229 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T18:33:53,229 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-20T18:33:53,322 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721633
2022-01-20T18:33:53,322 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.3655014038086|#Level:Host|#hostname:MeshifyC,timestamp:1642721633
2022-01-20T18:33:53,323 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0723114013672|#Level:Host|#hostname:MeshifyC,timestamp:1642721633
2022-01-20T18:33:53,323 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721633
2022-01-20T18:33:53,324 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20564.3984375|#Level:Host|#hostname:MeshifyC,timestamp:1642721633
2022-01-20T18:33:53,324 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:12129.4453125|#Level:Host|#hostname:MeshifyC,timestamp:1642721633
2022-01-20T18:33:53,324 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:37.1|#Level:Host|#hostname:MeshifyC,timestamp:1642721633
2022-01-20T18:33:54,118 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Listening on port: None
2022-01-20T18:33:54,119 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - [PID]21048
2022-01-20T18:33:54,119 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-20T18:33:54,119 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change null -> WORKER_STARTED
2022-01-20T18:33:54,119 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Python runtime: 3.8.12
2022-01-20T18:33:54,119 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change null -> WORKER_STARTED
2022-01-20T18:33:54,121 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:33:54,121 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-01-20T18:33:54,127 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-01-20T18:33:54,129 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642721634129
2022-01-20T18:33:54,129 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642721634129
2022-01-20T18:33:54,144 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - model_name: nice_dbert, batchSize: 1
2022-01-20T18:33:55,380 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Transformers version 4.12.5
2022-01-20T18:33:57,481 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Transformer model from path C:\Users\adib\AppData\Local\Temp\models\b1a1ed1a2bb74a19836be9061a5a412a loaded successfully
2022-01-20T18:33:57,485 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3341
2022-01-20T18:33:57,485 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3341
2022-01-20T18:33:57,486 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-20T18:33:57,486 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-nice_dbert_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-20T18:33:57,486 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - W-9000-nice_dbert_1.0.ms:4444|#Level:Host|#hostname:MeshifyC,timestamp:1642721637
2022-01-20T18:33:57,486 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - WorkerThreadTime.ms:16|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:35:50,567 [ERROR] nioEventLoopGroup-3-1 org.pytorch.serve.http.HttpRequestHandler - 
java.net.SocketException: Connection reset
	at sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:394) ~[?:?]
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:426) ~[?:?]
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253) ~[model-server.jar:?]
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1134) ~[model-server.jar:?]
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350) ~[model-server.jar:?]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [model-server.jar:?]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [model-server.jar:?]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [model-server.jar:?]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [model-server.jar:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:34:35,264 [INFO ] pool-2-thread-2 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51502 "GET /ping HTTP/1.1" 200 4
2022-01-20T18:36:09,259 [INFO ] pool-2-thread-3 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51512 "GET /ping HTTP/1.1" 200 1
2022-01-20T18:34:53,334 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721693
2022-01-20T18:36:21,199 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:35:50,567 [ERROR] nioEventLoopGroup-3-1 org.pytorch.serve.http.HttpRequestHandler - 
java.net.SocketException: Connection reset
	at sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:394) ~[?:?]
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:426) ~[?:?]
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253) ~[model-server.jar:?]
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1134) ~[model-server.jar:?]
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350) ~[model-server.jar:?]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) [model-server.jar:?]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [model-server.jar:?]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [model-server.jar:?]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [model-server.jar:?]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [model-server.jar:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-20T18:36:21,213 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.36425399780273|#Level:Host|#hostname:MeshifyC,timestamp:1642721693
2022-01-20T18:36:21,211 [INFO ] pool-2-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:36:21,213 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.073558807373|#Level:Host|#hostname:MeshifyC,timestamp:1642721693
2022-01-20T18:36:21,215 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721693
2022-01-20T18:36:21,215 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20285.21875|#Level:Host|#hostname:MeshifyC,timestamp:1642721693
2022-01-20T18:36:21,215 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:12408.625|#Level:Host|#hostname:MeshifyC,timestamp:1642721693
2022-01-20T18:36:21,215 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:38.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721693
2022-01-20T18:36:21,336 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721781
2022-01-20T18:36:21,348 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.36139678955078|#Level:Host|#hostname:MeshifyC,timestamp:1642721781
2022-01-20T18:36:21,350 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.076416015625|#Level:Host|#hostname:MeshifyC,timestamp:1642721781
2022-01-20T18:36:21,351 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721781
2022-01-20T18:36:21,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20244.5390625|#Level:Host|#hostname:MeshifyC,timestamp:1642721781
2022-01-20T18:36:21,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:12449.3046875|#Level:Host|#hostname:MeshifyC,timestamp:1642721781
2022-01-20T18:36:21,365 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:38.1|#Level:Host|#hostname:MeshifyC,timestamp:1642721781
2022-01-20T18:36:53,332 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721813
2022-01-20T18:36:53,332 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.36555099487305|#Level:Host|#hostname:MeshifyC,timestamp:1642721813
2022-01-20T18:36:53,334 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0722618103027|#Level:Host|#hostname:MeshifyC,timestamp:1642721813
2022-01-20T18:36:53,334 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721813
2022-01-20T18:36:53,335 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20062.828125|#Level:Host|#hostname:MeshifyC,timestamp:1642721813
2022-01-20T18:36:53,335 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:12631.015625|#Level:Host|#hostname:MeshifyC,timestamp:1642721813
2022-01-20T18:36:53,335 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:38.6|#Level:Host|#hostname:MeshifyC,timestamp:1642721813
2022-01-20T18:37:53,340 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721873
2022-01-20T18:37:53,340 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.36457443237305|#Level:Host|#hostname:MeshifyC,timestamp:1642721873
2022-01-20T18:37:53,341 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0732383728027|#Level:Host|#hostname:MeshifyC,timestamp:1642721873
2022-01-20T18:37:53,342 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721873
2022-01-20T18:37:53,342 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19363.8984375|#Level:Host|#hostname:MeshifyC,timestamp:1642721873
2022-01-20T18:37:53,342 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13329.9453125|#Level:Host|#hostname:MeshifyC,timestamp:1642721873
2022-01-20T18:37:53,343 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.8|#Level:Host|#hostname:MeshifyC,timestamp:1642721873
2022-01-20T18:38:53,334 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721933
2022-01-20T18:38:53,334 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.35518264770508|#Level:Host|#hostname:MeshifyC,timestamp:1642721933
2022-01-20T18:38:53,336 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0826301574707|#Level:Host|#hostname:MeshifyC,timestamp:1642721933
2022-01-20T18:38:53,336 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721933
2022-01-20T18:38:53,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19484.05078125|#Level:Host|#hostname:MeshifyC,timestamp:1642721933
2022-01-20T18:38:53,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13209.79296875|#Level:Host|#hostname:MeshifyC,timestamp:1642721933
2022-01-20T18:38:53,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.4|#Level:Host|#hostname:MeshifyC,timestamp:1642721933
2022-01-20T18:39:53,327 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721993
2022-01-20T18:39:53,327 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.35319519042969|#Level:Host|#hostname:MeshifyC,timestamp:1642721993
2022-01-20T18:39:53,328 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0846176147461|#Level:Host|#hostname:MeshifyC,timestamp:1642721993
2022-01-20T18:39:53,328 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642721993
2022-01-20T18:39:53,329 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19471.21875|#Level:Host|#hostname:MeshifyC,timestamp:1642721993
2022-01-20T18:39:53,329 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13222.625|#Level:Host|#hostname:MeshifyC,timestamp:1642721993
2022-01-20T18:39:53,330 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.4|#Level:Host|#hostname:MeshifyC,timestamp:1642721993
2022-01-20T18:40:14,397 [INFO ] pool-2-thread-4 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51636 "GET /ping HTTP/1.1" 200 1
2022-01-20T18:40:14,397 [INFO ] pool-2-thread-4 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:40:53,326 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722053
2022-01-20T18:40:53,326 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.35190963745117|#Level:Host|#hostname:MeshifyC,timestamp:1642722053
2022-01-20T18:40:53,327 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0859031677246|#Level:Host|#hostname:MeshifyC,timestamp:1642722053
2022-01-20T18:40:53,327 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722053
2022-01-20T18:40:53,328 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19481.69140625|#Level:Host|#hostname:MeshifyC,timestamp:1642722053
2022-01-20T18:40:53,328 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13212.15234375|#Level:Host|#hostname:MeshifyC,timestamp:1642722053
2022-01-20T18:40:53,328 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.4|#Level:Host|#hostname:MeshifyC,timestamp:1642722053
2022-01-20T18:41:22,116 [INFO ] nioEventLoopGroup-3-4 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51668 "GET /models/noop HTTP/1.1" 404 1
2022-01-20T18:41:22,116 [INFO ] nioEventLoopGroup-3-4 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:41:29,401 [INFO ] nioEventLoopGroup-3-5 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51670 "GET /models/nice-dbert HTTP/1.1" 404 0
2022-01-20T18:41:29,402 [INFO ] nioEventLoopGroup-3-5 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:41:48,060 [INFO ] nioEventLoopGroup-3-6 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51671 "GET /models/nice_dbert HTTP/1.1" 200 50
2022-01-20T18:41:48,060 [INFO ] nioEventLoopGroup-3-6 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:41:53,330 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722113
2022-01-20T18:41:53,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.3482437133789|#Level:Host|#hostname:MeshifyC,timestamp:1642722113
2022-01-20T18:41:53,331 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0895690917969|#Level:Host|#hostname:MeshifyC,timestamp:1642722113
2022-01-20T18:41:53,332 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722113
2022-01-20T18:41:53,332 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19465.78515625|#Level:Host|#hostname:MeshifyC,timestamp:1642722113
2022-01-20T18:41:53,333 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13228.05859375|#Level:Host|#hostname:MeshifyC,timestamp:1642722113
2022-01-20T18:41:53,334 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.5|#Level:Host|#hostname:MeshifyC,timestamp:1642722113
2022-01-20T18:42:53,329 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722173
2022-01-20T18:42:53,329 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34799575805664|#Level:Host|#hostname:MeshifyC,timestamp:1642722173
2022-01-20T18:42:53,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0898170471191|#Level:Host|#hostname:MeshifyC,timestamp:1642722173
2022-01-20T18:42:53,331 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722173
2022-01-20T18:42:53,331 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19468.625|#Level:Host|#hostname:MeshifyC,timestamp:1642722173
2022-01-20T18:42:53,331 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13225.21875|#Level:Host|#hostname:MeshifyC,timestamp:1642722173
2022-01-20T18:42:53,332 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.5|#Level:Host|#hostname:MeshifyC,timestamp:1642722173
2022-01-20T18:43:53,322 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722233
2022-01-20T18:43:53,322 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34778213500977|#Level:Host|#hostname:MeshifyC,timestamp:1642722233
2022-01-20T18:43:53,323 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.090030670166|#Level:Host|#hostname:MeshifyC,timestamp:1642722233
2022-01-20T18:43:53,323 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722233
2022-01-20T18:43:53,324 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19476.03125|#Level:Host|#hostname:MeshifyC,timestamp:1642722233
2022-01-20T18:43:53,324 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13217.8125|#Level:Host|#hostname:MeshifyC,timestamp:1642722233
2022-01-20T18:43:53,324 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.4|#Level:Host|#hostname:MeshifyC,timestamp:1642722233
2022-01-20T18:44:53,329 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722293
2022-01-20T18:44:53,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34551620483398|#Level:Host|#hostname:MeshifyC,timestamp:1642722293
2022-01-20T18:44:53,331 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0922966003418|#Level:Host|#hostname:MeshifyC,timestamp:1642722293
2022-01-20T18:44:53,331 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722293
2022-01-20T18:44:53,331 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19397.6484375|#Level:Host|#hostname:MeshifyC,timestamp:1642722293
2022-01-20T18:44:53,332 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13296.1953125|#Level:Host|#hostname:MeshifyC,timestamp:1642722293
2022-01-20T18:44:53,332 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.7|#Level:Host|#hostname:MeshifyC,timestamp:1642722293
2022-01-20T18:45:53,330 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722353
2022-01-20T18:45:53,331 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34976959228516|#Level:Host|#hostname:MeshifyC,timestamp:1642722353
2022-01-20T18:45:53,331 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0880432128906|#Level:Host|#hostname:MeshifyC,timestamp:1642722353
2022-01-20T18:45:53,332 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722353
2022-01-20T18:45:53,332 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19398.37109375|#Level:Host|#hostname:MeshifyC,timestamp:1642722353
2022-01-20T18:45:53,332 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13295.47265625|#Level:Host|#hostname:MeshifyC,timestamp:1642722353
2022-01-20T18:45:53,333 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.7|#Level:Host|#hostname:MeshifyC,timestamp:1642722353
2022-01-20T18:46:53,336 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722413
2022-01-20T18:46:53,337 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.35294342041016|#Level:Host|#hostname:MeshifyC,timestamp:1642722413
2022-01-20T18:46:53,338 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0848693847656|#Level:Host|#hostname:MeshifyC,timestamp:1642722413
2022-01-20T18:46:53,338 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722413
2022-01-20T18:46:53,338 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19403.28515625|#Level:Host|#hostname:MeshifyC,timestamp:1642722413
2022-01-20T18:46:53,339 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13290.55859375|#Level:Host|#hostname:MeshifyC,timestamp:1642722413
2022-01-20T18:46:53,339 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.7|#Level:Host|#hostname:MeshifyC,timestamp:1642722413
2022-01-20T18:47:53,332 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722473
2022-01-20T18:47:53,332 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.35349655151367|#Level:Host|#hostname:MeshifyC,timestamp:1642722473
2022-01-20T18:47:53,333 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0843162536621|#Level:Host|#hostname:MeshifyC,timestamp:1642722473
2022-01-20T18:47:53,334 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722473
2022-01-20T18:47:53,335 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19378.43359375|#Level:Host|#hostname:MeshifyC,timestamp:1642722473
2022-01-20T18:47:53,335 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13315.41015625|#Level:Host|#hostname:MeshifyC,timestamp:1642722473
2022-01-20T18:47:53,335 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.7|#Level:Host|#hostname:MeshifyC,timestamp:1642722473
2022-01-20T18:48:37,665 [INFO ] pool-2-thread-5 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54340 "GET /ping HTTP/1.1" 200 0
2022-01-20T18:48:37,666 [INFO ] pool-2-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:48:53,344 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722533
2022-01-20T18:48:53,344 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.35030746459961|#Level:Host|#hostname:MeshifyC,timestamp:1642722533
2022-01-20T18:48:53,345 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0875053405762|#Level:Host|#hostname:MeshifyC,timestamp:1642722533
2022-01-20T18:48:53,345 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722533
2022-01-20T18:48:53,346 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19251.83203125|#Level:Host|#hostname:MeshifyC,timestamp:1642722533
2022-01-20T18:48:53,346 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13442.01171875|#Level:Host|#hostname:MeshifyC,timestamp:1642722533
2022-01-20T18:48:53,347 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:41.1|#Level:Host|#hostname:MeshifyC,timestamp:1642722533
2022-01-20T18:49:49,006 [INFO ] nioEventLoopGroup-3-8 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54369 "PUT /predictions/nice_dbert HTTP/1.1" 404 0
2022-01-20T18:49:49,007 [INFO ] nioEventLoopGroup-3-8 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:49:53,333 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722593
2022-01-20T18:49:53,333 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34667587280273|#Level:Host|#hostname:MeshifyC,timestamp:1642722593
2022-01-20T18:49:53,335 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.091136932373|#Level:Host|#hostname:MeshifyC,timestamp:1642722593
2022-01-20T18:49:53,336 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722593
2022-01-20T18:49:53,336 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19311.22265625|#Level:Host|#hostname:MeshifyC,timestamp:1642722593
2022-01-20T18:49:53,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13382.62109375|#Level:Host|#hostname:MeshifyC,timestamp:1642722593
2022-01-20T18:49:53,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.9|#Level:Host|#hostname:MeshifyC,timestamp:1642722593
2022-01-20T18:50:53,336 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722653
2022-01-20T18:50:53,336 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34992599487305|#Level:Host|#hostname:MeshifyC,timestamp:1642722653
2022-01-20T18:50:53,337 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0878868103027|#Level:Host|#hostname:MeshifyC,timestamp:1642722653
2022-01-20T18:50:53,338 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722653
2022-01-20T18:50:53,338 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19261.56640625|#Level:Host|#hostname:MeshifyC,timestamp:1642722653
2022-01-20T18:50:53,339 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13432.27734375|#Level:Host|#hostname:MeshifyC,timestamp:1642722653
2022-01-20T18:50:53,339 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:41.1|#Level:Host|#hostname:MeshifyC,timestamp:1642722653
2022-01-20T18:51:07,248 [INFO ] nioEventLoopGroup-3-9 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54379 "GET /models HTTP/1.1" 200 1
2022-01-20T18:51:07,248 [INFO ] nioEventLoopGroup-3-9 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:51:53,327 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722713
2022-01-20T18:51:53,327 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34708786010742|#Level:Host|#hostname:MeshifyC,timestamp:1642722713
2022-01-20T18:51:53,329 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0907249450684|#Level:Host|#hostname:MeshifyC,timestamp:1642722713
2022-01-20T18:51:53,329 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722713
2022-01-20T18:51:53,329 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19487.1171875|#Level:Host|#hostname:MeshifyC,timestamp:1642722713
2022-01-20T18:51:53,330 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13206.7265625|#Level:Host|#hostname:MeshifyC,timestamp:1642722713
2022-01-20T18:51:53,330 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.4|#Level:Host|#hostname:MeshifyC,timestamp:1642722713
2022-01-20T18:51:56,522 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642722716522
2022-01-20T18:51:56,522 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642722716522
2022-01-20T18:51:56,523 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend received inference at: 1642722716
2022-01-20T18:51:56,523 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Received text: 'Duracell AAA Batteries: The Duracell CopperTop Triple A alkaline battery is designed for use in household items like remotes, toys, and more.
2022-01-20T18:51:56,523 [WARN ] W-9000-nice_dbert_1.0-stderr MODEL_LOG - Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
2022-01-20T18:51:56,523 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:51:56,524 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Duracell guarantees these batteries against defects in material and workmanship. Should any device be damaged due to a battery defect, we will repair or replace it at our option.
2022-01-20T18:51:56,525 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:51:56,525 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Long Lasting Power: Duracell alkaline batteries are designed and developed for long lasting performance.
2022-01-20T18:51:56,525 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:51:56,526 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Guaranteed for 10 years in Storage: Duracell AAA alkaline batteries are guaranteed for 10 years in storage.
2022-01-20T18:51:56,526 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:51:56,526 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Duracell CopperTop batteries are available in Double A (AA), Triple A (AAA), C, D and 9V sizes.
2022-01-20T18:51:56,527 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:51:56,527 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Volunteer firefighters devote their time to protect you and your co mmunity. Duracell's Power Those Who Protect Us donation program lets you give back to these selfless heroes
2022-01-20T18:51:56,528 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:51:56,528 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Made in USA
2022-01-20T18:51:56,528 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:51:56,528 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Mercury Free'
2022-01-20T18:52:00,316 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - This the output size from the Seq classification model torch.Size([1, 45])
2022-01-20T18:52:00,316 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3794
2022-01-20T18:52:00,316 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - This the output from the Seq classification model SequenceClassifierOutput(loss=None, logits=tensor([[-3.2243, -4.9792, -3.8304, -2.2234, -3.8829, -2.2154, -1.6881, -4.6233,
2022-01-20T18:52:00,316 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3794
2022-01-20T18:52:00,317 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          10.7528, -2.0183, -1.2838, -2.7602, -2.7446, -2.1360, -2.9151, -2.1613,
2022-01-20T18:52:00,317 [INFO ] W-9000-nice_dbert_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54402 "PUT /predictions/nice_dbert HTTP/1.1" 200 3799
2022-01-20T18:52:00,317 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -2.7576, -4.3672, -3.9853, -1.9807, -2.6290, -3.8076, -3.8929, -5.0999,
2022-01-20T18:52:00,318 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:52:00,318 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.job.Job - Waiting time ns: 91300, Backend time ns: 3796472700
2022-01-20T18:52:00,318 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -4.5872, -2.9971, -4.6625, -2.1394, -5.9834, -4.7561, -6.3381, -3.8472,
2022-01-20T18:52:00,318 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.job.Job - Waiting time ns: 91300, Backend time ns: 3796472700
2022-01-20T18:52:00,319 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -4.2865, -4.6237, -3.4589, -5.7397, -2.6901, -3.6226, -5.6384, -4.7645,
2022-01-20T18:52:00,319 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:52:00,319 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -5.0224, -1.5063, -5.9905, -5.2842, -3.9498]], device='cuda:0',
2022-01-20T18:52:00,320 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:52:00,320 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -        grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)
2022-01-20T18:52:00,321 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:3791.95|#ModelName:nice_dbert,Level:Model|#hostname:MeshifyC,requestID:2c64d1ae-5e21-42a3-b49a-b2671c023c08,timestamp:1642722720
2022-01-20T18:52:00,321 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3791.95|#ModelName:nice_dbert,Level:Model|#hostname:MeshifyC,requestID:2c64d1ae-5e21-42a3-b49a-b2671c023c08,timestamp:1642722720
2022-01-20T18:52:33,491 [INFO ] pool-2-thread-6 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54414 "GET /ping HTTP/1.1" 200 1
2022-01-20T18:52:33,491 [INFO ] pool-2-thread-6 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:52:38,067 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642722758067
2022-01-20T18:52:38,067 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1642722758067
2022-01-20T18:52:38,068 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Backend received inference at: 1642722758
2022-01-20T18:52:38,068 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Received text: 'Duracell AAA Batteries: The Duracell CopperTop Triple A alkaline battery is designed for use in household items like remotes, toys, and more.
2022-01-20T18:52:38,068 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:52:38,069 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Duracell guarantees these batteries against defects in material and workmanship. Should any device be damaged due to a battery defect, we will repair or replace it at our option.
2022-01-20T18:52:38,069 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:52:38,069 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Long Lasting Power: Duracell alkaline batteries are designed and developed for long lasting performance.
2022-01-20T18:52:38,069 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:52:38,070 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Guaranteed for 10 years in Storage: Duracell AAA alkaline batteries are guaranteed for 10 years in storage.
2022-01-20T18:52:38,070 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:52:38,070 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Duracell CopperTop batteries are available in Double A (AA), Triple A (AAA), C, D and 9V sizes.
2022-01-20T18:52:38,071 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:52:38,071 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Volunteer firefighters devote their time to protect you and your co mmunity. Duracell's Power Those Who Protect Us donation program lets you give back to these selfless heroes
2022-01-20T18:52:38,071 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:52:38,072 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Made in USA
2022-01-20T18:52:38,072 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - 
2022-01-20T18:52:38,073 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - Mercury Free'
2022-01-20T18:52:38,123 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 56
2022-01-20T18:52:38,123 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - This the output size from the Seq classification model torch.Size([1, 45])
2022-01-20T18:52:38,123 [INFO ] W-9000-nice_dbert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 56
2022-01-20T18:52:38,123 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG - This the output from the Seq classification model SequenceClassifierOutput(loss=None, logits=tensor([[-3.2243, -4.9792, -3.8304, -2.2234, -3.8829, -2.2154, -1.6881, -4.6233,
2022-01-20T18:52:38,123 [INFO ] W-9000-nice_dbert_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54421 "PUT /predictions/nice_dbert HTTP/1.1" 200 56
2022-01-20T18:52:38,124 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          10.7528, -2.0183, -1.2838, -2.7602, -2.7446, -2.1360, -2.9151, -2.1613,
2022-01-20T18:52:38,124 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:52:38,125 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.job.Job - Waiting time ns: 40900, Backend time ns: 58329600
2022-01-20T18:52:38,124 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -2.7576, -4.3672, -3.9853, -1.9807, -2.6290, -3.8076, -3.8929, -5.0999,
2022-01-20T18:52:38,125 [DEBUG] W-9000-nice_dbert_1.0 org.pytorch.serve.job.Job - Waiting time ns: 40900, Backend time ns: 58329600
2022-01-20T18:52:38,125 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -4.5872, -2.9971, -4.6625, -2.1394, -5.9834, -4.7561, -6.3381, -3.8472,
2022-01-20T18:52:38,125 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:52:38,126 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -4.2865, -4.6237, -3.4589, -5.7397, -2.6901, -3.6226, -5.6384, -4.7645,
2022-01-20T18:52:38,126 [INFO ] W-9000-nice_dbert_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:MeshifyC,timestamp:null
2022-01-20T18:52:38,127 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -          -5.0224, -1.5063, -5.9905, -5.2842, -3.9498]], device='cuda:0',
2022-01-20T18:52:38,127 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_LOG -        grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)
2022-01-20T18:52:38,128 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:55.36|#ModelName:nice_dbert,Level:Model|#hostname:MeshifyC,requestID:92e0258c-0e3d-437d-adf7-4b8975799e51,timestamp:1642722758
2022-01-20T18:52:38,128 [INFO ] W-9000-nice_dbert_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:55.36|#ModelName:nice_dbert,Level:Model|#hostname:MeshifyC,requestID:92e0258c-0e3d-437d-adf7-4b8975799e51,timestamp:1642722758
2022-01-20T18:52:53,343 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722773
2022-01-20T18:52:53,343 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34736633300781|#Level:Host|#hostname:MeshifyC,timestamp:1642722773
2022-01-20T18:52:53,344 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.090446472168|#Level:Host|#hostname:MeshifyC,timestamp:1642722773
2022-01-20T18:52:53,344 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722773
2022-01-20T18:52:53,345 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17163.41796875|#Level:Host|#hostname:MeshifyC,timestamp:1642722773
2022-01-20T18:52:53,345 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:15530.42578125|#Level:Host|#hostname:MeshifyC,timestamp:1642722773
2022-01-20T18:52:53,345 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:47.5|#Level:Host|#hostname:MeshifyC,timestamp:1642722773
2022-01-20T18:53:53,348 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:27.3|#Level:Host|#hostname:MeshifyC,timestamp:1642722833
2022-01-20T18:53:53,348 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34851837158203|#Level:Host|#hostname:MeshifyC,timestamp:1642722833
2022-01-20T18:53:53,349 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0892944335938|#Level:Host|#hostname:MeshifyC,timestamp:1642722833
2022-01-20T18:53:53,350 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722833
2022-01-20T18:53:53,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17119.99609375|#Level:Host|#hostname:MeshifyC,timestamp:1642722833
2022-01-20T18:53:53,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:15573.84765625|#Level:Host|#hostname:MeshifyC,timestamp:1642722833
2022-01-20T18:53:53,352 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:47.6|#Level:Host|#hostname:MeshifyC,timestamp:1642722833
2022-01-20T18:54:53,333 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722893
2022-01-20T18:54:53,334 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34713363647461|#Level:Host|#hostname:MeshifyC,timestamp:1642722893
2022-01-20T18:54:53,335 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0906791687012|#Level:Host|#hostname:MeshifyC,timestamp:1642722893
2022-01-20T18:54:53,335 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722893
2022-01-20T18:54:53,336 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17166.390625|#Level:Host|#hostname:MeshifyC,timestamp:1642722893
2022-01-20T18:54:53,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:15527.453125|#Level:Host|#hostname:MeshifyC,timestamp:1642722893
2022-01-20T18:54:53,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:47.5|#Level:Host|#hostname:MeshifyC,timestamp:1642722893
2022-01-20T18:55:53,348 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722953
2022-01-20T18:55:53,348 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.34297561645508|#Level:Host|#hostname:MeshifyC,timestamp:1642722953
2022-01-20T18:55:53,349 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.0948371887207|#Level:Host|#hostname:MeshifyC,timestamp:1642722953
2022-01-20T18:55:53,350 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722953
2022-01-20T18:55:53,350 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17005.15625|#Level:Host|#hostname:MeshifyC,timestamp:1642722953
2022-01-20T18:55:53,350 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:15688.6875|#Level:Host|#hostname:MeshifyC,timestamp:1642722953
2022-01-20T18:55:53,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.0|#Level:Host|#hostname:MeshifyC,timestamp:1642722953
2022-01-20T18:56:53,341 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MeshifyC,timestamp:1642723013
2022-01-20T18:56:53,342 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:83.3329086303711|#Level:Host|#hostname:MeshifyC,timestamp:1642723013
2022-01-20T18:56:53,343 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:847.1049041748047|#Level:Host|#hostname:MeshifyC,timestamp:1642723013
2022-01-20T18:56:53,343 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:91.0|#Level:Host|#hostname:MeshifyC,timestamp:1642723013
2022-01-20T18:56:53,344 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17010.296875|#Level:Host|#hostname:MeshifyC,timestamp:1642723013
2022-01-20T18:56:53,344 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:15683.546875|#Level:Host|#hostname:MeshifyC,timestamp:1642723013
2022-01-20T18:56:53,344 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.0|#Level:Host|#hostname:MeshifyC,timestamp:1642723013
